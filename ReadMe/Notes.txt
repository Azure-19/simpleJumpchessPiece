游戏引擎学习笔记	（未解决的问题由[WARNING]标记，请在项目中寻找）（不是跟课程抄的我会用[LOG]在本日志中标记）（Episode表示跟课程；Maintain表示自行维护和查询更新）
--------------------------------------------------------------------------------------------------------------------------------------------------------
Episode_01-引擎的入口就应该由引擎定义
1）在sandbox项目里创建一个application类来定义和启动我们的程序
2）我们要把dll导入导出函数写成方便的宏
3）堆分配是因为它真的很大，而且他几乎是游戏生命周期的全部，我们使用一个头文件来让Sandbox连接到GameEngine
3）入口程序用extern声明将在应用端实现的CreateApplication,让客户端实现
4）由于app连接了Engine.h,所以头文件可以在Engine.h里就引入；EntryPoint.h虽然标不认识报错，但是由于引用实际上的复制代码特性，共同编译时就会连接

--------------------------------------------------------------------------------------------------------------------------------------------------------
Episode_02-创建一个日志系统吧！
1）先下载spblog库（带有C#风格的c++库），由于只需要include,于是复制到Engine\src\vendor下，让Engine跟Sandbox都从全局包含这个路径
2）我们把它宏化，一是可以统一Engine的风格，二是可以方便条件编译
3）为了使用spdlog，我们像glew一样先过去抄一段示例，颜色等等初始化方面是抄了cherno的
4）只用了include里面的头文件，但是也要注意spdlog::stdout_color_mt的头文件是"spdlog/sinks/stdout_color_sinks.h"，刚刚忘记包含找了十几分钟问题
5）宏化不只是为了方便代码，还有在跨平台或者是发布release版本时去除日志系统的需求（c++,opengl见过好多次了）
6）暂且放在EntryPoint里面测试，然后跟Sandbox一起编译运行，我们希望在调用时不需要用stb::什么的，于是装进了Engine的命名空间，把它本地化了
7）（...）和__VA_ARGS__都是多变量的意思，方便输入一些不定长的不同格式的东西(

--------------------------------------------------------------------------------------------------------------------------------------------------------
Episode_03-为了用上构建系统
1）选择了premake（cmake似乎太过复杂），目的是跨平台，语言是lua脚本（猎）
2）总之跟着代码结构往下写
3）过滤器是到下个过滤器或是项目结束为止的
4）	filter { "system:windows", "configurations:Release" }
		buildoptions "/MT"				相当于属性里面选好了运行时多线程库
5）Absolutely weird,,,,,但是sandbox大部分就可以复制粘贴，因为使用了宏
6）抄写出来无法加载项目，显示
C:\Dev\C++\GameEngine\Engine\Engine.vcxproj : error  : 尝试在条件“'$(UseOSWinMdReferences)' == '' and ('$(TargetPlatformWinMDLocation)' == '' and '$(TargetPlatformIdentifier)' == 'Windows' and '$(TargetPlatformVersion)' > '7.0')”中对计算结果为“Latest”而不是数字的“$(TargetPlatformVersion)”进行数值比较。  C:\Program Files\Microsoft Visual Studio\2022\Community\MSBuild\Current\Bin\amd64\Microsoft.Common.CurrentVersion.targets
抄写了一个具体版本解决了
7）项目文件非常乱输出目录之类的完全错了
万事大吉，检查出几处拼写错误，文件路径错误，最后是版本错误（我搜索了最新版本，然而我的电脑上其实根本没有这个版本），现在premake可以正常工作了。
8）拼写检查太少，还有一处问题是configuration-architecture我只指定了x64，然而它的输出目录依然叫做x86-x64，不理解，事实上也不打算兼容32位

-----------------------------------------------------------------------------------------------------------------------------------------------------------
Episode_04-计划一个事件系统
1）这次是纯会议方式的，不妨加深一下对事件系统的理解
2）关闭窗口，是否改变大小，输入事件（键盘鼠标）等等
3）Application创建了Window，Window通过Win32API等等知晓了窗口事件，但是Application应该完全未知于Window（APP指针不能给Window）
	那么Window为了令Application知晓事件，就需要创建一种回调的事件（比如Engine::Event)来告诉Application
	实现是Application提供了回调的内容，Window来调用回调，这样就巧妙地让Application解决了以上的问题
4）阻塞事件：当我们处理一件事情，其他事情都被静止了（C#那个也见过），以后可能要列出一些清单来让非阻塞实现
5）为了方便实现事件，我们就需要让Application、layout等等这些做一个IEventListener, 监听所有事件
6）每个事件也需要取好名字，分好类，更重要的是创建基础类和继承类
7）另外，我们也要做一个事件调度器，让每个事件走到它所属的那个函数中去(function pointer)
8）最后我们就要进入窗口系统，来让它能够发挥作用

--------------------------------------------------------------------------------------------------------------------------------------------------------------
Episode_05-事件系统的实现！
1）因为代码量激增，不再是一边敲一边教了，先试着抄一遍再看讲解吧
2）正因为代码量增多了，我们也需要把一些标准库的东西整合放到一些地方，最好是使用预编译头（
3）用了几个宏来把重复很多的代码包起来了（方便多态为虚函数提供实现，方便让使用方式变得更加直观，等等）
4）虚函数保留也是为了多态，能让我们只有一个指针或者引用就可以得知它是什么（也是事件调度器Dispatcher的东西
5）思路都是在Event分类的基础上在各类创建出衍生类，或是特定的新的基类（比如键盘类共通点是键位，鼠标按键类共通点是哪个键之类的），
		用inline来保护函数，很多可以复制粘贴，特别是有共通点的衍生类
6）构建出了完整的体系之后，重载了操作符，也写好了事件调度器，方便从统一接口Event开始对所有事件进行调用
7）tmd 出大问题，spdlog一直说什么使用了未定义的结构体什么的，说我的类输出没格式化，但我输出的不就是一个string吗 我有一点不能理解了
8）查下fmt.dev和github，git上面有重载的时候命名空间混乱之类的无法正确选择什么的
9）发现问题在调用打印的时候发生，仅仅创建并不会不通过编译
10）格式化问题，这个宏接受对象作为参数时发生错误，进而发现是操作符重载工作的不好，
	不仅如此，我还发现WindowResize...那个类ToString没有标记const override							--(不妨下载一个旧版本？)
		，不是重载问题，可能是fmt的格式化出错了，暂且标记然后继续吧（在视频011底下有评论解释）--->姑且先使用e.ToString()!!--debug修改前前后后花了四五个小时

------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Episode_06-开始使用预编译头
1）.cpp是vs需要的;;在premake里面新增pchheader "pgpch.h"				上面是各编译器都要的，下面是vs才要的，相当于启用并指定pch
									pchsource "Engine/src/pgpch.cpp"

2）为每个cpp文件包含预编译头文件egpch.h

---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Episode_07-窗口抽象和GLFW
1）抽象窗口是为了支持多平台做准备（写了却只用于Windows也不坏）
2）终于要来到图像了，很激动！昨天花了太多时间debug之类的，虽然是弄清楚了一些原理但是这对限时编写游戏引擎整体的目的弊大于利，如果实在无法就应该让步，参看开头日后解决
3）决定编写多平台的窗口类，抽象它们的API，也为日后更换具体的api做准备
4）找到cherno添加的glfw，（他做好了cmake什么的），改写premake5文件，添加到项目里面来，，里面
-- Include directories relative to root folder (solution directory)				
IncludeDir = {}
IncludeDir["GLFW"] = "GameEngine/vendor/GLFW/include"			//为了解决日益增加的包含需求，直接用table来包含目录

include "Hazel/vendor/GLFW"					//为了连着里面的premake一起包含
5）所以，写下的Window.h里面的Window类提供的完全是虚方法，也没有它自己的成员，纯虚内容，是一个接口，必须由不同的平台具体实现
6）而在他之前留下了一些基本的窗口属性结构体（类似一种数据结构吧
7）设定指针是为了便利glfw触发回调		不知为何EG_CORE_INFO未被识别---------------->因为Log.h已经加入预编译头了，我还未来得及更改
8）逻辑就是：在Application初始化时初始化m_Window同时由于调用Window::Create(),glfw等等的初始化已经完成可以打开窗口，于是调用一次OnUpdate
9）问题是LINKerror，但是在视频底下有解释（云blade的翻译视频）
10）先试用了/NODEFAULTLIB:libucrtd.lib发现带来的问题比原来还多
11）是的  问题就是：cherno已经更新了数次Commit，而我在下载glfw时不小心下载了最新的版本，我应该按照相应的日期下载

----------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Episode_08-窗口事件和发送GLFW事件
1）我们要让窗口进行收集和反馈，这样我们就可以处理，目的就是连接05和07两个内容，这样我们就可以让引擎有一定的反馈了
2）先尝试实现关闭按钮！然后，我们还要能够调度其他的事件
3）从Window.h里面触发的SetEventCallback需要以某种形式传回Application，所以我们在构造函数里面加上m_Window->SetEventCallback(m_Window&)
4）为绑定事件，使用了std::bind,回忆一下，窗口回调里面使用了WindowData这个数据结构，
5）奇怪？我的lambda怎么坏了？--->哇  我多打了一个括号，是的 为什么Lambda不需要两个括号呢？不知道 抄写的时候也没抄明白
6）明白了，函数体其实是lambda的，为了避免整函数指针，用lambda直接完成了这个函数
7）写了非常非常多的函数之后呢，可以实现各种的循迹了，但是我们事实上还没有写任何的其他的回调函数，这也就是说我们的回调测试成功，目前可以向里面添加功能了
8）尝试使用事件处理器,成功了！就是又发现一个地方true写错了。现在我们实现了计划的结构，让窗口对Application一无所知了，
	从window出发给到glfw，通过回调函数（接受一个Event引用）跟Application里面的函数绑定，让Application来完成这次回调，很优雅

-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Episode_09-Layer stack->层，想想ps，sai之类的，或者是书页，堆叠控件之类的，有顺序的，所以也是stack
1）现在我们的情况是，每个层都是打开可用的，只有一个游戏循环正在无限运行，置顶渲染就要在最后渲染.其实这太好理解了，旧的被新的覆盖了
2）事件却是相反的，我们从底层向上一层一层渲染，但是最上的一层却是第一个接收事件的层（不妨类比用户和设备之间传递信息的物理方向）
3）因此我们要正着过去渲染，反着回来处理，是一个比较抽象的东西和各种的层级概念，但这样更好理解
4）比如底下的游戏层，上层就是一些正交投影ui之类的或者是什么ImGUI之类的
5）总之放码过来，，发行版里面层应该没有名字
6）layer.h其实很简单，用虚方法描述了它的一些行为，因为有子类所以用虚析构函数
7）layerstack用vector数组是因为想要正向和反向遍历的迭代器，同时也可以中间插入一些东西	
8）层其实也为application所有，因为当弹出层由推入层时它不会被销毁，只是暂时的离开层栈				Event.h里面对handle的可见性做出了修改，应该是有些函数需要调用
		staticruntime设置可以在premake网站上面找到，就在vs里面才要用
		不出意外的话就要出意外了，现在更新回调日志无法正确输出。  是否目录？Engine.h->Engine/Layer.h没问题啊，但是在Application里面没能调用sandbox重写的函数
		妈的，原来是我忘记在Sandbox类里面初始一个ExampleLayer对象了，无语!
	
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Episode_10-建立IMGUI->Step1 现代Opengl
1）hhhhh真的很简单吗 我还不是很懂，四天速成的，我记得当时用的是GLEW库，现在我们要用GLAD库（悲，那哥们不是白学了一些指令，虽然理论上应该是一样，听说更现代）
2）https://glad.dav1d.de/，我们在这里下了C/C++，gl4.6核心配置的glad
3）又出现构建错误了，我真的很讨厌premake了现在===因为我看不懂也不会排错,只会照抄，事实上也就是把glfw的照搬然后删了一点点之类的
4）总之搞好了，我们现在要在初始化窗口的时候接入opengl。噢 我知道了，我提前抄了一部分premake，但是我没有在项目里更新一些包含，所以我才会搞错，
		我确实没有弄明白这几个库的本质，他们其实本来就是从显卡驱动里面带出函数而已，两个库一起用难免会存在一些冲突
5）因为glad跟glfw都有opengl的函数之类的，所以一次就包含一个这样，，那么现在我们就安装好了Opengl
6）在调试的过程中可以通过调用一些最基本的函数来看它的值看它是否正确初始化来一般性验证

------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Episode_11-建立IMGUI->Step2 把IMGUI加入引擎！
1）我们终于要开始渲染一些东西了！这也绝对是之后开发的基础之一，问题也是要一点一点解决的，，，今天我们要做的事情是hack(什么玩意---->就是抄+乱搞的投机取巧，不太安全
2）但是我们实现的方式是奇技淫巧（因为时间有限？），之后我们应该像opengl里面做合理抽象，，那么我们要有一个渲染器
3）但是，像Opengl系列一样，我们先做出来一个，之后才建立渲染器和类抽象
4）我们可以在每个层上渲染IMGUI，但现在似乎是在最上层渲染（调试计
5）在创建一个OpenGL的文件夹之后，成功把Imgui的两个文件经过修改放了进去，现在可以在GameEngine项目里面方便的引用而不担心三个库打架了
6）很经典的，先创建一个上下文，而且可以在imgui的example文件里面glfw-opengl3找到一些示例代码来修改编写渲染器（找源码抄鼠标映射什么的
7）用了一个非常简陋的单例来初始化窗口大小（用application传来的值
8）不要忘记把层绑定起来噢，否则的话就没调用这个函数，什么都显示不了了
9）cherno留了个小练习，实现层解绑，但是好像没什么时间做喔，有些想法了，但是决定不做，主要是在Application.cpp里面增加两个出栈的函数，调用detach，
		然后再把glfw删除之类的还有*结束上下文*写在detach里面，这样子应该能完成一轮；；；；但是cherno要让完整实现事件系统，
		我感觉还是比较困难的，主要是时间紧，本身理解也不强，大概要花一整天，不过这么做好处很多就是了，不妨思考十分钟，想到一个最基本的方案
-------先审视事件系统，它的核心应该说是一个dispatcher，把事件分类，用模板函数call到不同的事件处理函数中去；，目前只是一个打印系统，真正实现的其实只有移动窗口之类的
	application的onevent目前有核心控制台打印追踪，然后是一个层迭代器反向的处理（因为我们现在可能会拥有两个层了这个很有用），
	为了让IMGUI能够和事件系统整合起来，我们还需要把按键码本地化以便调用，接着应该是把ImGuiLayer::OnEvent接入到Application,然后让dispatcher发挥作用，把对应的event
		加上具体的实现，这样就能粗略的完成IMGUI事件

---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Episode_12-建立IMGUI->Step3 加入IMGUI事件
1）我们要把事件系统加入到层系统中了，学会阅读glfw的文档确实比较重要
2）看到glfw的实现，如果按下某个键呼叫回调，就把某个key设置成true之类的，我们一边借鉴一边实现，先做主要的内容
3）先使用dispatcher，来吧事件转发给其中一个具体函数，实现其实应该是让event交给库去做
4）看到具体函数可以想象得出来，我们做的就是得到.h里面什么的有的一个对象，取回他的引用把他的引用取出来设为真，，return false应该是并不消耗这个事件，现在还没做到层判断
5）不知道为什么鼠标滚轮的作用失效了，标记一下------，还好暂且不需要，可以忽略---已经完成见Episode_17 8),原理貌似是把滚轮事件交回给imgui（（
6）添加keytype事件的时候就可以找到glfwcallback在WindowsWindow.cpp中实现
7）IMGUI实现了！，但是我们还有一些不当的包含和之前的hack操作，我们将在日后慢慢地改进它！

---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Episode_13-了解github和pull request！

									因为没空也很少使用，所以空着---主要是一些团队协作的问题，集思广益不要固执己见之类的


---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Episode_14-轮询输入->（在事件以外也能查询是否输入了，，比如按下alt甩鼠标会怎么样）
1）那么我们先实现Input类，再来一边码一边学吧
2）噢噢 我们会跟Window.h一样，只是做一个接口类再在Windows文件夹里面实现它，不同的是这会是一个单例（全局静态对象）
3）我们的目的就是聚焦当前窗口，处理活动窗口（未来可能有多窗口）,按键码问题可能会在下一节解决
4）---**Input用public静态成员函数提供一个接口来访问protected的纯虚函数（=0），其会在派生类中实现**---但我们想要得到GLFWwindow目前得不到（Window类私有成员）
5）我们首先不可能public，那有点可怕；如果用友元那不算坏，因为可以绑定Input跟Window了；当然提供一个public方法也是可行的方案，为了支持多平台添加了代码
6）在Window.h添加纯虚接口，在windowswindow.h中实现的时候依然加virtual跟override纯粹是代码的好习惯了
7）见识到了c++17很酷的元组取元素写法。   *把Input的实例在WindowsInput里面创建初始化为空指针，
	然而最后选择直接 Input* Input::s_Instance = new WindowsInput();  因为这样初始化也不错

---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Episode_15-鼠标键盘按键码，
1）为了跨平台扩展，本引擎的统一性和客户端对引擎/之类的可见性构建一套按键码，比如我们不想要让平台特化的库或者是只处理一些特性的库在客户端，我们不想它们深度绑定，于是解耦
2）同时为了生态之类的可以采用条件编译，同时统一的名字也会方便我们使用，然而映射有时候也是很重要的（跨平台使用保存数据之类的
3）选择静态保存一套glfw的码也有好处，而且glfw的码本身跟ascii码也有一些相通之处
				--[LOG]--:跟着cherno的commit把runtimelibrary更改了，现在是Debug和Release

---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Episode_16-数学->渲染前置
1）为了解决一些向量、矩阵的运算问题，我们需要一些数学的东西，比如一个数学库。
		但是对于像Engine这样比较大的引擎，数学库的好坏极大程度影响它的性能，所以我们来装glm(opengl math)它的语法基于GLSL之类的，总之先用起来吧
2）	glm装好了（premake愈发熟练），我们有非常多的警告没有处理（不知什么时候处理），然后也测试了一些基本的功能并且也可以知道它没有太大问题。
3）		但是呢，glm有非常非常多的别名，这个应该是对纹理坐标和直接坐标之类的区分，在观察代码的时候需要注意
4）准备为矩阵和向量添加新的日志输出方式吧，就像我们对event对象做的那样（虽然tostring暂且丢不掉）-------（暂时没有做）
5）

----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Episode_17-IMGUI停靠和视口（调整，恢复，提高）
1）使用IMGUI的“新”特性（因为我下载的已经是六年前cherno的版本了），但是我会说，2019年的东西已经足够好，只要能够稳定地将它实现这就是好的
2）这两个特性就是从窗口里拖出新窗口，把窗口吸靠在边框上，等等（这也是一种锻炼吗）     去到github找到大概五年前转成brunch的文件安装
3）我们采取的策略是在Engine的Imgui里面创建一个.cpp，让它包含所需的文件，成为编译的载体，真可惜 我们会把当时建立的ImGuiLayer事件全部删除
4）imgui的实现里面已经把按键码处理好了所以我们可以删掉，把它的实现搬到imguilayer.cpp里面来
5）我们几乎把所有的事件处理跟回调删除，换成了Begin()跟End()两个函数，我们就可以在处理一些控件跟层的时候获得方便，中间是render函数
6）另外，我们要把创建imgui层的权限收回引擎，继续中心化
7）所以我们在application.h定义了一个指向imguilayer的unique指针，然后在.cpp里面把他唯一实例化，这样就做到了让imguilayer由engine来掌控
8）我们的代码变成	m_ImGuiLayer->Begin();				
					for (Layer* layer : m_LayerStack)			也是为创建渲染线程之类的做准备
						layer->OnImGuiRender();								现在这个imgui可以拖出来了，滚动也没问题了（虽然是通过事件删除完成的）
					m_ImGuiLayer->End();
9）但是唯一指针是不行的，这样会把所有权交给LayerStack，后者也就决定了它何时被创建何时被删除（但是我们不想）因此应该换成原始指针
10）层栈的遍历方式从iterater->index			这次的代码不太优雅，不过无伤大雅，接下来很快来到渲染		
					-[LOG]-听说会有内存泄漏问题，我在析构函数上加了一些停止的函数

----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Episode_18-渲染
1）---本节是->会议式的，主要也了解一下渲染到底是怎么样的（是的我在opengl系列里面也没有特别弄懂，只是基本上边抄边看了解了一些，和我c++学了半吊子有些像）
		介绍了一些gpu渲染的原理， 谈了一下不同的接口（没办法 ，把opengl作为一个开始对我来说也是有一定难度的，其他的接口暂时是绝对做不出来的，不妨先一切从简。
			还介绍了一些有关多种图形接口抽象的东西

----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Episode_19-渲染架构
		会议式			谈了我们引擎想要的一个通用接口RendererAPI跟实际的图形渲染接口RenderAPI的界限问题，也就是抽象到什么程度的问题
				因为不同平台的图形接口不同，图形渲染的指令也有比较大的差别，我们做的通用接口越通用，可能也会越难用，
				所以我们要把握抽象的度的问题，让通用接口发挥简化作用的同时不会无差别的让各种接口没有发挥空间，同时也可以为没有一些功能的图形接口添加（比如Opengl）
				让最可能用到的（偏爱的）接口成为某一种规范，其他的接口则共享这种规范
1）我们从最简单的OpenGL开始（API简单导致需要用它的设计感更强）--- 
2）第一步 完成渲染的接口（Opengl系列对吧） 第二步 用这些接口来编写特定的渲染器
3）维护这个接口是一个比较长的过程，而且它们之间的依赖关系并非绝对，像opengl系列中完成一部分接口，完成一个简单的渲染器再慢慢地拓展它是我们的新计划
4）譬如形状，纹理，材料、、、、甚至是其他的新的接口比如DirectX12 Vulcan之类的

-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Episode_20-渲染？维护？！
1）偶尔维护代码，修正一些潜在问题是非常必要的（如果我个人做了的话，我会添加[LOG]的标记，如果是比较严重的会标记为[Warning]）
2）			解决了Episode17留下的小问题(但是我已经在Hazel分支里面成功的把他解决了)主要是IMGUI库链接的问题
		主要的原因是：在用户端Sandbox里叫出的IMGUI的.Begin()/.End()在Engine里其实没有使用，而Sandbox按dll链接Engine，它会找不到这个符号
		简而言之，engine.dll会自动删除来自静态库的没有被引用的内容
3）-[LOG]-为imgui的premake文件添加了crt_secure_no_warnings；；；后续发现修改无效，应该到engine里面imguibuild.cpp里
4）很多的warning都是因为跨界使用了dll之类的，但是没有办法，除非把engine重构为静态库。但是因为后续要用热加载的脚本所以不打算把c++部分变成热加载
		也可以通过脚本拉入函数来防止这些跨界，但是总而言之这一部分也是随便聊聊

-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Episode_21-解决问题
1）		cherno最终决定把engine更换为lib，因为我不是很懂lib跟dll之间的区别所以我也只好跟着一起吧所有的warning去掉同时顺便学一学这是什么
					总之就是要把engine跟.exe文件最终静态链接起来（对性能之类的有帮助）
2） 修改premake文件，改成staticlib等等       -[LOG]-engine的premake.lua把版本(10.0.22621.0)改成了latest,release开启优化
3）改了以后warning更多了，吓人，顺便把所有ENGINE_API瘫痪了，这样子确实把相当一部分的问题解决了。只剩下旧函数问题跟fmt问题，cnm
4）我决定忽略这些问题
--	使用已移动的 from 对象: user_chars (lifetime.1)      vendor\spdlog\include\spdlog\pattern_formatter-inl.h	1319	
			函数 fmt::v10::detail::num_significand_bits<double> 是 constexpr，如果需要编译时计算，请将变量 num_float_significand_bits 标记为 constexpr (con.5)。	GameEngine	vendor\spdlog\include\spdlog\fmt\bundled\format.h	1636 2842 3326 3660 
			函数 fmt::v10::detail::num_significand_bits<double> 是 constexpr，如果需要编译时计算，请将变量 significand_mask 标记为 constexpr (con.5)。	GameEngine	C:vendor\spdlog\include\spdlog\fmt\bundled\format-inl.h	1251	
5）总之算是解决了		-[LOG]-于总premake文件Gameengine项目中windows下增加了buildoptions { "/wd26498" }

-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Episode_22-渲染之路01->创建渲染上下文
1）glfw的开启上下文的类是今天的目标，它会接受一个窗口句柄，然后处理它
2）我们需要自己的上下文是因为这个引擎的目的不仅仅是简单的只对opengl vulcan之类的有支持，还有对DirectX之类的支持，所以需要义无反顾地抽象（前几个episode）
3）除了窗口特定的渲染上下文， 可能还会取一个静态的开启上下文  ，，目前先保持简单（？） 也就是让Engine统一一个窗口
4）		此后不需要ENGINE_API了（因为不再按照dll来编译，in episode21),,，目前渲染器的一部分叫做GraphicsContext.
5）回到Windowswindow，创建上下文的时候应该要用Windowpros，包含了context.h，因为实际设置窗口的地方
6）		和opengl系列有一些不同的是，我们还没有实际写完画出图形的代码，选择的做法是在使用了少量的传统opengl的基础上先给出渲染上下文，准备像现代opengl的形式靠拢
7）			最后在OpenGLContext.cpp里面实现Init方法之类的时候，我们把glad库顺势从windowswindow里移除，这样子就消除了它对这个库特定的依赖，也实现了一定程度上的抽象
		譬如我们想实现三个接口ABC，不可能把ABC的依赖库都放到那个.cpp里面，然后写三个不一样的方法；比较好的想法应该是写一个比较抽象的方法，编译时判断是哪个接口，于是连接实现.cpp
8）Opengl用的是gl4.6，核心配置，所以没办法用隐式顶点数组的方式即时渲染，不过这没关系，在构建好了这些东西之后就可以像Opengl系列那样渲染一些东西了，
		需要做的按钮类之类的东西还没有头猪，，可能要暂缓了

-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Episode_23-渲染之路02->画出三角形
1）和Opengl系列一样，先用数个接口画出来之后再慢慢写成类
2）写一个着色器是相对比较大的工作量，暂时可以用默认着色器，注意，用的是一个比较取巧的方法，变量直接写在Application.h中了，比如m_VertexArray,m_VertexBuffer(管理ID）	
3）对gl代码理解加深了。-[LOG]-应该是每一帧按绑定的顶点缓冲区的的状态来画，statemachine特性了
4）drawelements时不传indexbuffer，是因为vertexbuffer和indexbuffer绑定的状态没有消失
5）-[LOG]-我将 glGetString(GL_VENDOR)强行转换为(const char*)，因为按照cherno会触发断言错误
6）可以在nv面板中来让引擎首选nv的图形处理单元（但是在离电的情况下按asus的默认给上amd的cpu是非常方便的，因此我没有选择）

-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Episode_24-渲染之路03->OpenGL着色器
1）图形管道是什么，怎么渲染图形？马上jump in some codes，来试图构建顶点着色器和像素着色器
2）我们怎么处理顶点数据？用到矩阵，opengl的绘图原理主要还是沿着渲染管道：先给顶点着色器（每个顶点运行一次），然后传给像素着色器（每个像素运一次）
	实用角度上，应在cherno的基础上加入一些自己想要的功能，目前为止还没有为渲染接口创建特定类。
		c++小复习：基类的析构函数要标记虚函数避免二次释放，但是目前由于只有opengl，只有一个类；opengl小复习：很多时候解绑不是必要的，因为换绑方便且省时
3）官网抄的代码里面有一些检查的东西，用断言和core_error处理了，分别编译vertexshader和fragmentshader成功之后执行连接操作。
		编译成功之后其实就不再需要源文件了（譬如生成了二进制），因此让它们分离出去，保持一个比较空闲的状态。和opengl有些不同的是着色器编译已经移动到类中了
4）		维护一个m_RendererID来跳出作用域，在不同函数中访问它。-[LOG]-我把program全部换成了m_RendererID
	使用unique指针没必要一直用make_unique,但是shared指针应该用make_shared因为需要分配一些内存进行计数。
			还没有用文件流弄，但是改进了用原始字符串str = R"()";，这样不用加非常多换行符
5）vertexattribpointer第一个参数的0对应顶点着色器layout(location = 0)欸。  着色器里面给vec3+0.5会让每个分量都增加0.5; vec4可以用(vec3, vec1(或者一个float))来加起来表示
		在像素着色器中访问顶点着色器的位置变量并且改下颜色、渲染管道的一步，酷。 opengl小复习，顶点着色器用out后片段着色器用in可以传递变量varying variable.
6）利用数学变换和用顶点坐标绘制，实现了渐变的效果，事实上，它用的是插值的办法

-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Episode_25-渲染之路04->重走抽象之路：渲染接口
1）抽象之路不仅是为了方便编写时简化一些重复操作；还是为了支持多接口多平台。由于我的知识并非深厚，会抄写cherno的代码然后可能只会略微增加/减少一些方法
	很大的区别是编译时还是运行时选择渲染接口（譬如opengl和directx），比如对照什么的就是运行方便，编译就是引擎的性能更好
2）运行时可能是用一个虚类做纯接口，引给OpenglShader跟DirectXShader，但是给到客户端那只是一个叫做shader的东西，这样就完成了不错的抽象--
	只需要做创建、绑定、上传同一变量即可，不把复杂的实现带下来。接口设计想法就是通过配置(ifdef什么的)来把绝对用不着的接口文件滤掉。
	在视觉方面-vs写c#用visual编辑究极方便，希望也能引入。文件比较多难以管理，所以vertexbuffer和indexbuffer可能合并管理，合理的合并不坏.
3）用的是空析构函数而不是=0，有些在意，后者应该是彻底禁止这种基类使用这个函数的意思吧。用建立一个指针的方式实现了多态的“构造”函数，在它的实现里决定接口等等无限制传参问题
4）vertexbuffer类有非常多操作的空间（譬如光线追踪等等）GL_ARRAY_BUFFER譬如一个唯一的那类buffer，它与指定的buffer代号绑定
	缺少renderer类，创建之类的函数空着，难以搞定，而且很多函数命令没有这个类比较难用，为了把它抽象进去需要先建立它。
	cpp小知识，enumclass和enum的区别：后者几乎是全局的，容易污染到其他地方同样名字的变量；虚函数后面加=0是纯虚，不能被实现，但是可以被继承.
	纯虚不能被override其实是如果函数声明时使用了override而实际上并未重写任何基类中的虚函数，则编译器会报错
	static在类里不和对象关联，也没有this指针，它们相对地全局，也不mutable，inline还需要有完整的定义（函数也只取body）
5）没有正确重载是签名写错了（忘记大写）；
6）为何renderer.h会报错没有找到预编译头。经检查是visualstudio发癫，因为我用.cpp模板创建的.h文件，他就以为要预编译头了
7）总之搞定了，这让创建一个顶点缓冲区和索引缓冲区更加抽象而好用
	-[LOG]-cherno希望我们把自己抽象顶点数组什么的作为作业，我会进行一个基础的尝试

-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Episode_26-渲染之路05->重走抽象之路：顶点缓冲区布局
1）顶点缓冲区布局其实就是告诉gl这个数组怎么分配，已经有些熟悉了，今天就要抽象它，，第0个属性，3个格式float，不需要格式化，一个顶点的大小，这个属性的偏移为0（或者nullptr
	glVertexAttribPointer(0, 3, GL_FLOAT, GL_FALSE, 3 * sizeof(float), 0); 这个东西opengl相当于是给出顶点数组自由，大顶点（包含所有）也可以，分开顶点属性设置数组分别绑定也可以
	最后保存到vertexarray中去。
2）因为和顶点缓冲区有关，也放到Buffer.h中去，-[LOG]-cherno希望枚举类型用hlsl风格的Float3，而我更喜欢Vec3。c++小知识，inline用来编译时把函数代码嵌入调用点而非进行调用，提高效率
3）  -[LOG]-所有Vec,Int->Vec1,Int1。   BufferLayout的构造用了许多隐式转换，为了能够方便传参，还是使用了const std::initializer_list<BufferElement>& element，
			来允许以{ {element1} }构造其中传参的过程也隐式地使用了BufferElement的构造函数
4）需要得到的Offset可以计算，但是Stride需要一个整体才能计算。使用遍历列表的办法。为什么呢？因为我们的初始化譬如
	BufferLayout layout = {
		{ ShaderDataType::Vec3, "a_Position" },			因为这是布局，计算的偏移量和步幅由这个顶点内所有属性共同决定，因此必须遍历，注意这不是遍历多个顶点，是遍历顶点内属性
		{ ShaderDataType::Vec4, "Color" }
	};
5）把layerstack的两个public迭代器复制过来，改成element迭代器，可以在application里更优雅的迭代（iterator），当然使用传统for循环也很方便（一个即用即销的index
6）通过抽象顶点缓冲区布局，里面的代码马上优雅了不少，也从晦涩难懂变得更加简单了

-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Episode_27-渲染之路06->重走抽象之路：顶点数组
1）由于用的核心配置，需要显式创建顶点数组，然后它们马上要被抽象，让顶点数组保存连接vertexbuffer和indexbuffer的状态
	opengl4.5之后有一些不错的新函数，可以让现在的迷惑操作更加自动化一些，日后再来探索。但是vertexarray在directx里面不真正存在，抽象方式很重要（来看看cherno的想法
	为了先完成opengl，选择牺牲了一些directx架构，做一个对opengl实现，对directx悬空处理的接口
2）少量地方用shared_ptr牺牲一些性能简单实现缓冲区计数之类的。m_RendererID往往保存在派生类里，接口保持没有成员变量
	写接口实现的时候一种用原始api而非本接口内部调用函数的习惯，然而传参的对象应当使用调用的函数，这样会更有逻辑。把application的自动化indexbuffer移到vertexarray里面
3）给vertexArray解绑也是为了不在其他作用域不小心把不相干的vertexBuffer绑在一起。另外vertexArray的创建函数(gl)也自动的把他绑定了
	绑定vertexarray就能用保存了的vertexbuffer(及其layout)和indexbuffer的属性
4）和buffer异曲同工，实现里反向引用一个接口相关的头文件（虽然目前只有opegl）把gl内容移动到实现在app被引用.h的cpp上让application实际上对opengl不可感，也抽象好了
		同时把unique_ptr全部换成了shared_ptr，统一的同时方便计数
5）cpp小知识，std::make_shared<template>只需分配一次，比new性能好一点，缺点是内存释放偏慢。		std::shared_ptr squareVB = std::make_shared<VertexBuffer>
																							(m_VertexBuffer->Create(squareVertices, sizeof(squareVertices) / sizeof(uint32_t)));		
	m_VertexBuffer->SetLayout({																						隐式地调用了构造函数吗，那先用reset方法吧，也可以创建
	{ ShaderDataType::Vec3, "a_Position" },	----好玩，利用BufferLayout的隐式创建，比较酷的东西
	});
6）传进去的float数组已经在离开作用域时被销毁了，但是它的状态依然还在vertexbuffer里面; 酷，我们回到矩形了，删除了application里面的vertexbuffer和indexbuffer（因为vertexarray
				给vertexarray添加析构函数

-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Episode_28-渲染之路07->重走抽象之路：渲染流，drawcall
1）重新抽象的小总结和给未来的引擎铺路之：渲染器和实际对象。
	我们先需要一个vertexArray,包含或是能引用vertexBuffer(also layout)和indexBuffer的状态；需要一个着色器，用来编译给gpu；
	如果要一个立方体，我们需要有相机，它的位置坐标，（获得这些需要转换矩阵）；它是什么纹理，是什么材质；在环境中看起来是怎么样，环境光源之类的，
	那么分成了两部分：环境（光线、相机、其他等等）、物体（位置、材质、变换等等）；渲染场景应该从一个相机看过去，渲染环境，把所有的对象按照一个参数渲染
	做beginscene(uniform之类的)，渲染所有网格，按照不同的变换矩阵丢进去shader，endscene，之后提交到渲染（流），之后按渲染线程计算。 
			把整个场景集齐之后可以批量化操作，创建渲染序列，做优化，多线程，等等等等
2）也就是说，我们要开始摆脱即时模式了，我们该进入今天的现代的渲染器了，创建RendererAPI.h接口
	渲染器变成高度抽象的类，处理场景、网格、高级构造；其他的工作将在它之下:我们重构了renderer.h
			-[LOG]-个人习惯是公共类型(enum class)，私有成员变量，公共成员变量，私有成员函数，公共成员函数，
3）RenderCommand和RendererAPI分开是希望后者不要太大，作为一个更高级抽象的接口类而存在，亦防止泄露，泄露顶多1字节
4）通过RenderCommand包含RenderAPI，然后又由Renderer包含，这样就能从Renderer里访问到一切需要的操作和参数(下而上)；同时由于RenderAPI带上了vertexarray
		标准库的头文件便可以一直复用下来，RenderCommand可以直接做成静态包装类直接实现需要的函数，这个暂时架构真是太简洁了
5）然后使用惯用技巧，在.cpp文件里包含平台特定的头文件，从这里开始区分不同平台并回到平台中去实现它。glm小知识，vec4的四个分量xyzw的别名是rgba
		-[LOG]-opengl应该有其他图元，也就是说我应该可以做这个跳棋的一些图像单元了
6）Renderer/api分发任务给下面的类，直接调用；因为只包含了Renderer，把api的定义部分复制，然后在Renderer分发回去即可(因为renderer里面保存了一个指针，精妙）
	-[LOG]-防止本人眼花，将在BeginScene和EndScene之间打括号；--------不要忘记在发出drawcall之前绑定vertexarray，cherno也忘了
7）Command不做太多事情，不妨丢给render来抽象它。      终于！完成了真正的目标，来让app里面所有的gl代码消失，不再需要包含glad
	cherno布置作业，让我们把它丢到sandbox里面去。   
----[简易思考01]---- how？我们应该在哪里发出渲染指令还是什么的？并非复制粘贴。  
			想办法把构造函数移出来？ 我们应该把它移到继承application的sandbox的构造函数中？发现访问权限会有一些问题，那么应该使用get函数吗？，应该要给一个get方法
			绕过vertexarray的保护，在sandbox里面能够访问到绑定之类的东西吧

-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Episode_29-渲染之路08->相机及其原理（计划）cherno鼓励写自己的相机系统，但我可能只会试着建立一个类概念
1）渲染时间是有限的，渲染的优化当然也可以来到相机中；相机也和游戏的行为发生交互，譬如移动人物；譬如相机提交渲染
	相机只是一个概念，怎么看一个场景的概念。我们的视野？（譬如视角，45~65°）我们观察的位置？   相机不存在，存在的是我们在这个情况应该提交什么数据给渲染器？
2）相机的移动显然要对整个场景的渲染产生影响，让所谓相机的后移变换为我们需要的object变换。比较基础的透视原理，然应reverse it，因为我们真正能够改变的是渲染的东西，而非观察的
3）日后应该要与网格有关。-- 现在，相机需要改变它的位置，需要view matrix：相机在3D空间中的变换；我们要渲染东西的话就应该反过来，求逆矩阵来对object做变换
4）transform rotation scale相机似乎是日后要用的手段，目前没有scale 就是transform×rotation，求逆
		3D的纵横比（用透视矩阵perspective matirx、投影矩阵projection之类的存储），消失点之类,；2D的时候用正交投影不同远近的物体应该大小一样
		projection × view × model × vertexposition是得到正确场景的算法，而在glm里是列主序的矩阵，应该是vp × model × view × projection
5）API是怎么运作的？我们有一个object，有一个相机，有它的位置，viewmatrix,projection view,可以在c++中直接计算； 但是object应该跟相机传来的矩阵一起处理（后者相对静态）
	vp × model是针对每一个物体的，往往要在顶点着色器里面完成。有了这整个乘法就是给到gl的真正的绘图顶点了，为什么是这样做呢（c++跟顶点着色器分开？）
	因为c++处理的部分只调用一次，所有物体都是通用的；而顶点着色器每个顶点都要调用一次，与vp × model匹配
6）一个场景从一个camara开始；；  我们可以用批处理（我没学到那里），不过如果用统一变量来吧view matrix上传，并非困难；
		保存一个实际维护的相机的引用可能会因为非法改变而危险；仅复制数据会更安全一些
7）uniform的上传还能为上传纹理材质之类的准备，它们都能交给渲染器处理
----[简易思考02]----what?也许按照同样的抽象方式，建立一个Camera.h\Camera.cpp，它是平台特定的？(DirectX需要的不一样) 再让OpenGLCamara继承它，
	按照RenderAPI的，简略地设置它。这个类需要给出视图矩阵跟什么的矩阵的话， 方法可能有ResetCamera，指定它的位置，GetMatrix得到需要的矩阵，构造时需要有初始值
	成员变量存两个mat4，可能还要静态Camera指针，一个就够了，在外部访问它的重构函数；重写beginscene，在里面处理camera，上传给着色器
	上传着色器的办法恐怕是共同变量uniform, 我们可能需要一个比较大的阵传上去；大概就先是这样？其实不明白正交相机是干嘛的，应该是像2D游戏那样水平地移动？
	我们移动相机就体现为渲染的画面向着某个方向移动了吧 大概是，那么和鼠标事件*拖拽（未实现），键盘事件持续移动会比较配，但是目前不把他绑定到事件系统中去，大概就是这样，我们手动改它的位置，			
								-------朋友，思考真的有用--------

-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Episode_30-渲染之路09->创建正交相机
1）camera本质上还是viewmatrix和projectionmatrix。我们可能可以把所有相机放在一个文件里（因为它们比较小，属性也比较相似便于管理
	c++小知识，const xxx&传参更安全，也适用于多数直接输入数字初始化的场景
2）我们需要输入一些矩阵？如果相机跟鼠标什么有关，我们就该在让它和事件绑定（猜对）；然而现在不需要（就这个项目而言也不需要）
	glm::ortho(left, right, bottom, top，远，近（z轴）)的远近使用默认值1，我们可以用0，0，cherno提供-1和   [头文件<glm/gtc/matrix_transform.hpp>]
3）创建了一个固定边界的相机，边界设定到-1.0 1.0之类的
4）果然要用到unifrom，gl着色器原来也有mat4类型.-[LOG]-我真的很想把着色器文件和绘图移出Application了，太多了
5）需要在.h里面用到的类定义就不要犹豫地在.h里面包含，至少它应该能工作才考虑是否能简化
6）由于矩阵求逆，把相机范围设大东西会变小（对的对的对的），但是纵横比例还没调，我们定义的正方形并非正方形（和窗口大小也有关系？）总共我们要设置相机跟窗口纵横比一样
			-[LOG]-创b点子2来了， good 它成功了.						submit顺便也把shader绑定自动化了，因为反正也要用相机上传统一变量;;;  太爽！
7）引用头文件时当心不要把#pragma once删了，报错都不知道在哪里标红捏-[]-还是没画出图形，原因是beginscene时传入camera却没有把本类保存的m_SceneData更新
-[LOG]-RecalculateViewMatrix函数算transform时glm::radians(m_Rotation)(转弧度吧大概)直接丢了rotation进去导致异常旋转....破案了，是没有初始化导致的;那个是角度转弧度函数
小作业  用鼠标键盘控制相机

-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Episode_31-维护架构？->把代码移动到Sandbox，尝试事件处理
-[]-小作业失败了，我不会在sandbox里面用layer或是什么其他东西来访问application。花了十来分钟做不到，抄，边抄边学吧！
1）Sandbox是我们期望的游戏本体，我们应该把和应用程序相关的放在这里面
2）把application无限循环里面的着色器相关的函数往外移没，留下层更新和imgui
怎么设法访问Applicatio的私有成员变量呢？     啊？    做法是把application相关的变量统统移出来？！   破案了 部分原因是太久没有更新Engine.h，我也没有想到要在其中扩展它，囿于可见性而又忘了
	把几乎所有抽象了的renderer塞到了Engine.h中，暴露给sandbox（也就是它可以部分接管application了）
	（其余未包含的要么被已包含的包含，要么没必要出现(上下文)），我看到了光明的未来，glm跟glad\glfw都不可见了
3）注意在sandbox里面就要Engine::了，因为没有namespace括着了，application的构造函数也发生了变化，（also ExampleLayer,  把初始化列表移过来）
4）因为sandbox会偷基类的构造函数，在它的构造函数里又调用测试层的构造函数，那么呢把application原来构造函数里面的着色器初始化代码丢到里面即可
5）为什么cherno要放到onEvent里而不是onUpdate里呢？  噢 不是用轮询的话可以用dispatcher，也不用在外面做一些奇怪的判断，可能可以节省一些性能？
		明白了，event那堆这只是一个给出基本功能的接口；如果想要用派生类的东西可以去询问dispatcher
6）回到application里面定义，当时有按层遍历，是否中断（阻止输入）之类的，所以当时会用bool OnEvent的函数
	噢 原来不用onUpdate还有计算deltatime的问题，太久我忘了；也就是和帧率对应（哪怕现在锁了60或是144）；不过onevent太卡了，只能一步一走
7）我原来试图从Input来呼叫Keypressevent并非问题，这居然是一个不错的实现，思考的好处
		旋转的时候相机似乎不是反着的了，为什么呢？因为逆时针才是正方向，和键位产生了一些认知冲突，所以不如就让速度反过来，符合认知
	 下一步也许做变换！ 期待着色器的抽象，我真的很想把着色器资源分到另外一边去了，回到gl的文件流。		现在已经能控制一些东西了，酷

-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Episode_32-更好的update->timestep/deltatime
1）我们的相机有什么问题？！这和帧率挂钩，如果固定每次刷新移动，对正常的时间就完全不同了，移动速度就会巨大的区别，不妨改成时基的，把cpu速度转换为现实世界时间的流逝
	我们已经用过了deltatime，把帧时间上传；但是如果不锁帧率这会出现问题吗？暂且不考虑的话，我们给出一些固定帧率，速度应该跟帧速率有关西；；
		如果60fps->30fps，每帧的速度翻倍即可，由于每帧渲染一次，帧数越高当然就越平滑了
2）-[LOG]-尽量不要尝试绕过这个问题，譬如锁帧之类的，那并不好，万一达不到呢？它虽然依然平滑，却让世界仿佛进入慢镜
3）怎么运行的时候测出一帧花了多少时间？用获取时间和存当前时间两帧间减法即可。
4）创建Timestep类可能只是为了可读性，而且c++可以在栈上创建
5）重载操作符（这次相当于类型强转  float()）能让timestep直接拿来当float加入运算了
6）可能为游戏引擎未来打好基础。我也不讨厌这种做法，固定时间什么的

-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Episode_33-渲染之路10->变换，如何把对象放置在其他什么地方呢？！
1）model matrix，描述objcet在世界的位置缩放旋转（mainly position），相当于引入一个辅助的参考系？ 来让我们的模型跟世界产生交互，需要一个transformation matrix（之前的原理对吗
		静态的model跟transform一起体现了一个物体在世界上应该怎么样
2）现在只是一个着色器提交什么的，交出我们想要的集合体然后在对象特定的变换中渲染他（每个网格的，每个对象的，却不是每个场景的）
	噢 是上次说的顶点着色器每次自动使用，，，这样会极大的重构我们的代码，着色器资源和其他的顶点文件什么的应该要存在了吗？	----  日后会更改成ECS吗
3）现在渲染的2D有点3D的方式，之后会让2D的跟3D区分；因为2D的往往复用可以一批一批地处理
			gl_Position = u_ViewProjection * u_Transform * vec4(a_Position, 1.0);就是pro*view*trans*pos的一般计算方式
4）酷，用嵌套循环画出了一个网格了，这是一种分批处理的方式吗？ 感觉还比较原始。缩放不需要总是经常计算，不妨用来当属性或是保存它
5）我们现在用的per object的方式是3D的方式，我们可能该统一一下材质，用相同的同一变量什么的，要批处理吗？（因为我的目的也是画出非常多重复的东西）

-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Episode_34-渲染之路11->材质系统
1）intro 我们为什么需要它？我们如果写一个根据input改变output的shader，它显然会变得更加强大，如果我们想要让绘制的东西看起来不错，确实就需要有现成的数据，，这就是材质？
	材质是啥？材质是shader&data/uniforms ，相当于一个固定的算法，输入不同的东西时显示出不太一样的性质，但是算法却一样（譬如颜色）
2）我们想要一些灵活性却不会牺牲它的性能，创建许多种着色器，给每个着色器部分自由，需要时再分别取用，这样效率会高一些。
	常常来说某些东西材质和几何总是绑在一起的，可能需要个材质类和给它的数据（统一变量），检查统一变量，创建常量缓冲区
3）测试性质的，突然发现我还不会用imgui欸。循环调用着色器提交变量看起来有点怪，日后应该会用材质系统搞定，这样更可读吧，什么应该归到材质里面？因为材质是一个物体的固有属性
4）应该找一种办法决定着色器设置什么统一变量
5）或者texture也可以一起	Engine::MaterialRef material = new Engine::Material(m_FlatColorShader);		//非常漂亮的api整合了纹理和材质之类的，我们对这个系统显然是充满向往
							Engine::MaterialInstanceRef mi = new Engine::MaterialInstance(material);

							mi->SetValue("u_Color", redColor);
							mi->SetTexTure("u_AlbedoMap", texture);
							squareMesh->SetMaterial(mi);
6）当然了我们现在还没有做着色器类，本期其实主要是介绍性质的

-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Episode_35-渲染之路12->着色器抽象和统一变量
1）shader类难写，因为其他的类也没好好建立，但是无论如何我们该把基础的东西移到一些比较好的分类地方，至少要有资源什么的，本来也是对着一个三角形不断重构螺旋上升的过程
2）大概七八期没有管过shader了，现在应该让它和opengl解耦了     ；本期尝试用imgui来测试动态更新统一变量，，虽然我们还没有材质接口，但是未来会有的
	纯接口类里面析构函数很多有	virtual ~VertexBuffer() = default;，和{}相比稍微安全一些
3）纯接口类不暴露上传函数的一种简单办法是弄出一个接口指针，在用的时候把它转换为有着上传函数的子类指针，譬如Buffer->OpenGLBuffer
	当然现在指针只是权宜之计，更何况这是一个原始指针或是什么奇怪的指针，之后应该要建立新的指针类
4）做了抽象类创建它使用已经准备好的Create函数,render里面submit暂时用了一个动态cast而非静态cast（见cpp学习记录，好搜索，语法糖，自动检查）；最后也要把submit的gl函数换掉
		一个好办法是用哈希表储存location，因为location实际上不会变（Opengl系列中用过
5）酷，imgui调试成功了

-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Episode_36-维护和构建->引用，作用域，智能指针？！--这一期深入浅出，很酷
1）智能指针的自动删除一般是基于对象什么的，之前提到的所有权问题就是阻止使用unique的原因。为什么要用智能指针？因为不然自己写很可能还没有标准库的好用
2）正常得到渲染提交之后不会立即开始渲染，我们需要拥有整个场景的上下文什么的，现在做到一半；总之和上次一样我们难以管理shader vertexarray什么的，我们需要得到这些资产什么的
3）我们需要多线程，我们要充分利用cpu的性能，我们要把渲染也丢到一个线程中处理；一边处理当前的数据，一边输出上一帧的数据，
	之后我们把examplelayer释放了，却发现着色器对象和顶点数组已经被删除了。要避免它渲染线程应当强引用对象，获得对象的所有权，共享指针计数的机制恰好能够做到
	共享指针、唯一指针、原始指针之类的性能开销差的部分在现代平台上往往可以忽略不记，我们使用指针的方式大概是权衡利弊，合理利用他们的强项，避免撞到它们的薄弱区
	（原始指针不规范使用，共享指针递增递减次数产生异常，唯一指针在不合适的地方过度了所有权）
4）共享指针用原子增量什么的用性能减少提供了线程安全，所以，提交给渲染线程的资产应该是有共享指针计数机制的，有些和窗口有关的唯一的东西可以用唯一指针
	我们简单封装一下它们的原因主要是给日后拓展开辟空间；以及代码美观unique->Scope   shared->Ref。同时这也不会太让人想不到这是何种指针之类的，
5）在core.h里面用模板简单封装之后日后想要拓展这个指针只需在core里面解决，不会伤筋动骨，非常美好
6）事实上这也是一个非常简陋的（渲染）资产管理系统，譬如共享资源无人需要时候就释放它
	我们需要区分Ref和其他只是用sharedptr，前者应该是资产asset（顶点数组着色器之类的）的东西才用，并且统一到资产管理系统中去

-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Episode_37-资产构建01->纹理-
1）回来了，回到gl的纹理基础：取贴图；但是有了一些更新。texture可以直接直接加载资产图片也，真是太好了。原理其实还是把缓冲区丢上去，或是上传贴图采样重回，存在vram里面
	而且纹理比想象中的还强大，包含非常多信息，即使是3D，甚至是基于物理的渲染，很多需要的数值可以从texture计算，甚至是储存在texture里，它不只是颜色什么的
2）把texture coordinates放进顶点属性（所以纹理当然会在某个几何上绘制）；给着色器sampler；c++侧负责绑定上传，准备纹理类
	在顶点数组里一个vec2（2D)按照正常坐标系来看。但是事实上gl从图里面（左上到右下）弄出来纹理坐标是垂直翻转倒过来（见opengl
3）创建一个纹理着色器（现在堆的有点多了).直接把纹理坐标拓展成vec4颜色输出可以用来验证可视化测试数据是否正确上传了.
4）纹理类文件架构也是一样。纹理有些不同的表现，创建一个基类（可能只是用来共享所有纹理都有的属性）。纹理类的基类不用构造函数，继承基类的类有构造函数（返回指针那种（也改换成Ref了吧）），但是依然是虚类（要交给特定接口实现），只加上自己方法 不重写基类虚方法（在实现类里重写即可）
5）跑去原来VertexArray复制粘贴修改了。这次改用了Ref，和之前的new方法也不一样，现在用make_shared了（日后应该会维护原来的
6）继承虚析构方法不需要override吗？。    资产文件大概率不是png之类的东西（虽然我不反对），总之在buildtime把原始文件变成自己的文件格式是很正常的（asset build pipeline）
	用的也是stb_image(同gl)（专注于那个头文件而已，所以直接偷来了（真是不好意思！） 
7）-[LOG]-测试用的01无法正常显示，sandbox目前shader跟texture的用法都是dynamiccast，转接口特定类来访问。
	   sampler2D其实只是表示了采样的插槽	std::dynamic_pointer_cast<Engine::OpenGLShader>(m_TextureShader)->UploadUniformInt1("u_Color", 0);  
	m_Texture = (Engine::Texture2D::Create("assets/textures/testTexture01.jpg"));不再使用reset方法，因为改成Ref之后已经是sharedptr了
感觉会用点debug了（进步了也），free的时候不小心取了指针的地址，铸币一个

		这次用的是RGB，不是RGBA---非常多信息可以在opengl的学习项目里面查到,应该说几乎只是拓展了一些

-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Episode_38-资产构建02->混合。纹理+（之后opengl就没学过了）
1）alpha通道事实上要看纹理是否有四个通道，不过png一般有四通道。现在先做同时支持三通道和四通道的处理（这就是混合和叠加吗？）

2）	第二次见识a & b，01234的小数字做逻辑与运算确实应该还是0和非0，有逻辑与的效果
3）如何混合？这包含一定的算法内容之类的。主要代表了我们希望什么图更占优势，图片是否透明度？应该会在渲染初始化中做
4）我们需要初始化渲染器的初始点
5）设置好开启混合，选好源函数和目标函数，整合在init里面
6）感觉代码非常多了，抽象程度很高，休息一会，仔细思考代码架构。

-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

-[LOG]-思考和总结：引擎的代码架构？
有几个系统？日志系统、事件系统、层系统&IMGUI、渲染系统、窗口和基础功能
窗口和基础功能core目前只管理帧；core.h管理编译，断言系统，typedef；windows.h窗口基础功能接口；input是轮询输入接口；application是主体，用产生单例的方式在入口点主循环中生存
日志系统比较简易，由log.h和log.cpp使用spdlog库完成，很多debug的好处
事件系统以Event.h为中心，Event是提供API的基类，Dispatcher是访问Event子类事件处理方法的方法（只有基本功能），在sandbox以onevent暴露
层系统提供分层功能，譬如ui交互层和游戏画面层。目前只用到了应用层和调试用的IMGUI层，有层的表和事件由上而下的触发机制，抽象方式engine->Windows，为sandbox提供onupdate
渲染系统最大最复杂，几乎每个部分都有像application一样create指针生存的处理（基于渲染平台，管理这个的类主要是RendererAPI），renderer内为纯虚接口，只提供基本的API，在OpenGL中才具体实现。不同的部分之间有依赖关系，rendererID贯穿始终（跟gl绑定的东西相关）。
	按照渲染需要的顺序，首先是两种Buffer（内括layout）、然后是vertexarray，这些缓存的数据走到RenderAPI；Renderer可以在这种时候初始化开启上下文，期间接受绘图指令，具体的绘图指令又是调用rendercommand来实现的，后者把它分发到opengl中去；绘图需要绑定的shader目前接受字符串并交由gl编译，同时负责上传统一变量，同样也把它包装，实现于opengl中；进阶的纹理采取同样的方式，用同样的泛型基类统领所有的texture。暴露给sandbox的
渲染系统用bind和unbind统一简化了操作，具体绘图操作在beginscene和endscene之间；渲染的指令被简化为submit并提供了丰富的扩展（scale等），texture的加入、相机与glm数学的应用令图像产生了更多更新的变化，现在的渲染系统有着接口集中，拓展性强，抽象程度高的特点（存在如texture的三重继承），寻找一个接口应该自上而下地观察修改。
	通过接口给了sandbox绘图的自由（创建上下文，提交绘图，上传统一变量，修改相机位置等）


-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Episode_39-资产构建03->着色器asset
1）写的时候在大计划里可以进行一些小尝试；具体写代码时先做出可用的东西，日后再重构它们（因为只是期待完美地完成它，最终招致失望） 
	今天要走的一小步是着色器source要更改为文件了；当然也可以保留从字符串编译着色器的方式（但是这不是让它变得简洁的方式）。日后希望把它预编译为二进制文件
2）Shader::Create(path)会更酷，而且可以让一个文件来提供。opengl跟directxcode似乎不一样，用着色器语言来命名似乎更符合常理（.c   .cpp .cs andso），当然也有可能有自己的格式
3）未来可能需求虚拟文件系统，但是现在先用c++的方式,,,std::ifstream in(filepath, std::ios::in, std::ios::binary二进制读取文件，因为没有必要以字符串读（这是额外开销）
4）和opengl中做的有点不同，使用了ifstream,读取的函数有些出入。也用了unorderedmap做preprocess，而非原本的phrase（多着色器的考虑）
5）preprocess还是有用std::string::npos这个东西.实际上的操作从字符串里读出着色器，但是用了一些不一样的string函数（本来是find什么的），最后用返回glenum的办法和opengl对接
6）第二次的编译错误是Sandbox里面当时为了出图象包含OpenGLShader.h，现在因为头文件里需要glenum包含了glad出事了，补救的办法是在openglshader.h里面直接定义一个glenum（不好
7）调试中。发现有忘记更改变量名的错误，另外一个是没有正确读取文件的错误?
			-[]-颠佬vs把我的in变大写了还弄不回去,逆天了，必须回车才能用,虽然我用各种换文件的方式顶住了，但下次如果也报错就看看


-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Episode_40-资产构建04->着色器库
1）这个引擎用来给非引擎工程师做游戏的话，就不应该让他们来更改着色器，这也就是要编写一个着色器库的原因。
	谈这个方面也要涉及每个人如何定义他们的引擎。我可能会在完成2D渲染之后修改它吧
2）上次的编译时代码vector带glshaderID的实现搞错了（不过能跑是有点抽象），导致一些内存问题或是着色器编译问题，stackarray跟着色器相性不好，不好弄。
3）内存分配有时宁愿把大量小数据存在堆上比在栈上好些，但是大多数情况下(尤其是频繁分配)array的性能都会更强，尽量避免用vector（但我好像没学array啊）
4）初始化时,和|仿佛没什么区别；shader类的纯接口不能变，shaderlibrary就是一个新的库
5）想要从名字访问着色器的时候为shader.h增设的GetName接口再次体现了这个接口的用法：创建函数创建派生类，把可能需要的存储都交给派生类处理
6）不太理解为何要加一个name和filepath都使用的add版本。   做了一些便利性接口和函数简化（这个可以理解，反正也是在debug里调用），shaderlibrary就算ok了
7）修复了shader.h的create方法的返回裸指针				-[LOG]-我可能会把其他没改到的裸指针也弄回去
8）shaderlibrary只可能持有一个所以没必要用共享指针在堆上创建。  简化着色器创建的例子：：auto textureShader = m_ShaderLibrary.Load("assets/shaders/Texture.glsl");
		把路径存进library，按名字随用随取，好东西

-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Episode_41-2D渲染器？--计划视频
1）回顾过去的代码，用时间加深理解。cherno view point
	现在已经有了一些需要的系统，想要用它做一个游戏已经可以了（只是还没有audio）
2）现在的上传和matrix和verticies都有3D的影子，这对一个2D的渲染器来说是不甚必要的。画的其实就是square，大不了用一个圆贴图搞定
3）让2D和3D的渲染分开，与其让beginscene和drawquad（四边形）变成2D，不妨避免API混乱，做renderer2D和renderer3D的分离
4）矩形占位跟圆贴图可能会有点用
5）BeginScene ;; submissions like  DrawQuad(pos, size, color, tex) ..  我们需要一大堆2D图像要怎么办？要做的是batching(批处理)，并非炫酷粒子效果，需要成百上千的图像时
	并非drawquad 几千次，而是上传合并动态缓冲来一次过画完，用BatchRenderer  10K，100K单元   60fps   texture.   ，哪怕用几十几百种材质来分别批处理这些单元也只用四到五次
6）texture也可以合并，然后读取一部分（槽位不够的话）这样可以让drawquad用的更少。（GPU天生就是干这个的）
	我们可能需要Animations，一些动画来配合move（用一种合并的texture序列来以此渲染之类的
7）需要渲染关键帧，追踪最近帧之类的技术。 。。。。我们也需要UI Layout（我真的很需要）   PAUSE, Resize,Quit,text，要和层系统重合
	锁纵横比？改纵横比？，hitbox之类的，渲染的框和文字？ 这些也需要包装一下。PARTICLE system 2Dexplosion，HDR（用些特效），可能还有dynamic lighting
	因为这为游戏而准备，因而2D渲染器会做的全面而有用，会有所有一个游戏该要有的东西。  可能需要scripting（方便操作，lua,c#...）
8）可能日后也会有ECS之类的系统（实体组件代替各种传统对象继承，数据跟行为分离）譬如   Player  -transform -2Drender-s
	可能需要很多时间，篇幅比较长（是的，到按钮还有多达40episode）

-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Episode_42-进入2D->相机控制器
1）谈谈sandbox怎么变成可以用来做2d游戏的sandbox。 游戏里面的相机比较灵活之类的，对看起来是否丝滑真的太有作用了，废话少说 跳进代码
2）让sandbox更健康也是好事，今天会强化相机。让数据和相机动作分离。因为和input之类的相关为了解耦相机类本身，把动作建立在另一个文件里让它包含一个这个类；
3）相机控制有窗口控制缩放控制，拖动窗口的时候在OnEvent里通过dispatcher分发给当前类覆写的onevent动态调整相机的纵横比；在滚动滚轮的时候用同样的思路重新调整缩放等级
4）这些操作是通过在Controller持有Camera类实例调用OrthographicCamera里提供了一个和构造函数功能相同的调整函数做到的,数据在controller里面经历一次中转
5）有点像继承，但是却是通过持有实例的方式进行，在sandbox里面直接持有一个新的这个控制类就相当于在拥有相机的同时拥有基础控制了I（当然sandbox里的控制就烧了）
6）黑屏->相机需要update（否则当然什么都看不到了）；还是黑屏->从创建回溯没有初始化m_Aspectratio导致的。cherno分析代码排查的思路
7）我的闪现出图像之后消失了（imgui出现之后产生的）一定是OnUpdate寄了
	是onupdate寄了，忘记更新pos导致它按初始化000了，还有高手？！噢  应该跟pos没关系，感觉是scale出了问题。。总之是onevent的问题，一旦用onevent就爆。。异常输入？
8）目前为止一切正常?加入了cherno的限制之后可以正常的事件和显示了但是还是会突然变大变小
	-[]-和之前IMGUI有点像鼠标滚轮输入出现了问题？（不是鼠标，拔了用笔记本的也有）。zoomlevel被异常设置（突然极大极小），暂时禁止此类事件
		鼠标的offset大的离谱，是否不小心用了mousemoved？是的！一旦出现鼠标移动事件Xoffset和Yoffset就离谱，IMGUI层正常
	----------用Ctrl+滚轮紧急修复中/。。。。。找到了，---在MouseScrolledevent中我将其设成了MouseMovedType----。。  修好了
	
	-[]-aspectratio被异常设置（溢出），窗口改变大小现被禁止
	-----------修好了，aspectratio不小心用了-=导致的无限减小

-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Episode_43-进入2D->调整尺寸(部分暂时性代码)
1）本期应该要重新做好窗口调整大小，设定视点：让gl知道渲染的范围（窗口修改大小，但未修改渲染大小。
	即便设定帧缓冲区，也要做这些来适应窗口改变（我可能会选择纵横比必须不被改变的窗口
2）先做一个能跑出来的东西。另外相机是否也根据窗口改变之类的 这些也是可以自主设定的（也有见过，但主要是缩放的做法，不修改视野）
	看到窗口类各种回调就有点晕了，之前就不太理解，基本是存放窗口数据+窗口回调的结构，具体的回调要用到glfw
3）resize里面这个event非常灵敏，拖动的每个瞬间都会得到新的大小，不过这个会阻塞线程。
	仔细观察会发现有些onevent在application里面实现(譬如关掉窗口，初步判定这种属于引擎服务（和sandbox的行为一样但是可以理论上可修改性不一样所以只保留重要的不修改功能即可
4）事件返回false应该是做完了的意思；每一层都要知道窗口大小改变了，比如现在就算最小化了还是在持续渲染就显然有点蠢,用一个minimized判断是否update即可
	IMGUI只是调试用所以就没有禁用，而且最小化之后IMGUI没有最小化而且完全就卡住不动了更蠢
6）cherno给出了展示更多/更少的解决方案，但我不会使用因为我觉得这样更好
		这么做的话就跑去cameracontroller里面去设置zoomlevel，而且因为没有锁定纵横比会显得比较麻烦
5）事实上在那个处理矩阵的地方已经处理了一部分了，如果同时纵横比不改变拖动就会放大；如果改变纵横比就会提供更大的视野，所以不妨忘记这件事
7）可能会想办法锁定一下纵横比吧 我不喜欢一些东西改变纵横比（这样我就会有空渲染了
8）-[LOG]-eventtype判断+auto& re = (Engine::WindowResizeEvent&)e;   试图自己分离事件处理的好办法

-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Episode_44-维护代码-目录结构项目构建等
1）重新组织文件，改进一些问题
2）总之就是要让之前弄好的代码以更好的方式存在，当然了，保持它运行会更重要一些。我的premake应该是最新的所以不用跟着升级，我将使用的就是vs2022
3）脚本用了pushd和popd来让脚本回到原来那个地方运作；而且可以让脚本进到文件夹里面整理
4）-[LOG]-批处理文件开头@echo off输出更少信息
5）是的 我也不想随便升级vs版本，有的代码可能在新版本不能很好运行了
6）把堆在engine外面的代码重新归类整理，但是cameracontroller放的位置有点随意，现在直接在renderer里面
7）-[LOG]-删除了所有定义的ENGINE_API（动态库才要的东西），统一用了default，还是没有改一些原始指针(可能因为不是资产？）
8）-[LOG]-没有乱动原始指针,然后cherno下一期就和我现在想改一样改了（之前没保存导致的

-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Episode_45-2D渲染器00->准备工作
1）拓展sandboxlayer来准备2D渲染的沙盒测试（现在只有一个简单的examplelayer
2）一些小排错的东西在分支的commit上面找可能会比较方便（也就是说我可以按照时间来大概查询一些我不是很懂或者是改不了的bug？）
3）sandbox里着色器代码烦2D渲染器，但是又是测试代码工具；所以创建一个新的层专门测试2D渲染器把原来的藏起来就好了
4）从sandbox里面挑着偷来一些代码（譬如有用的相机之类的），又准备重写Layer里面的onattach和ondetach(用来给Layerstack替代构造函数和析构函数)
5）另外也应该想想这些API做出来要怎么用，sandbox的examplelayer里面有不少ref所以我打死也不会全删的（大部分都是想要什么要什么就是了,而且也实现了不错的自动化了）
6）Engine.h里面带着Entrypoint，但是在sandbox项目里面要用就得包含他，这会导致main重定义，这是之前的问题，现在它要被拆出来
7）奇怪，我RGBA的A通道怎么不见了，IMGUI莫名其妙的问题----解决了，imguicoloredit3没改成4
8）总之是抄好了，干净

-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Episode_46-2D渲染器01->开始，准备一些简单的测试环境
1）vs有一些不错的调试工具，但是具体调试环境（和当时的LOG和断言之类的一样)还是在引擎中存在有帮助解决问题（因为引擎的架构和可能出现的问题点是可以自己掌握的）
	搭建一个性能调试工具，让engine在优化中更高效。    游戏引擎具体的实现可以从外面拿进来按照这个方式组织
2）-[LOG]-有空为shader提供set方法。。  尤其是Renderer类用静态的方法是因为这种方法跟它们的[实例]和[状态]其实没什么关系， 刚好cherno也解释了他这么做的理由
	设置static的意思是不需要一直保持一个实例，不用手持数据；；事实上很多创建函数就是用static便能用命名空间访问之；；一个目的可能是让它不需要实例就能叫出来，也好看
3）本意当然是让renderer和图形接口类型没关系，也让api更漂亮.  注意，renderer2D和原来那个比较原始的提供的接口有所区别了
4）把onattach的移到了Renderer2D的init中去，提供了一个struct来存数据（window），目前就直接放在里面.    cpp小知识，成员变量s_Xxx静态；m_Xxx类持有，指针的话不清楚
5）持有struct的之中呢来让自己可以手动删除，免得崩溃了
6）用立即模式弄出了图形，基本上从sandbox2D跟Renderer里抄来的。----另外在cpp里面好像不能整glm::vec3 position = {glm::vec2& pos, 1.0f};这种着色器语言能用的狠活
7）出现黑屏的时候也注意不要忘记查看统一变量（尤其是相机）

-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Episode_46-2D渲染器02->变换Transform
1）为了摆脱只能绘制一个固定东西的矩形，用quad的传参用变换矩阵的方式完成（位置大小；或是旋转）。shader接口增加了设置同一变量，不再需要用openglshader
2）-[LOG]-API从upload->set是因为会做更多操作，因为平台级抽象跳出opengl了不再标注uniform。决定api长什么样再去实现它,
			目前还没有统一缓冲区继承set把原来的upload包起来就可以了	
3）怪不得 这样就不用维护一个大的夸张的顶点缓冲区了，把变换放在drawquad中
4）很酷的一个小东西，原来其实应该也能实现但是是画之前要upload一次而且略有意义不明
5）事实上已经可以做一个小游戏了，但是看着引擎的api和抽象程度螺旋上升真的notbad

-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Episode_47-2D渲染器03->纹理
1）纹理的实现抄改颜色；-[LOG]-目前没做纹理*颜色；目前也没做数据结构（比如quad的pos size color tex，这个可以在游戏端引入）
2）总之先做一部分。-[LOG]-把3D的renderer也改成了setmat4这种接口（反正它包含2D的），把纹理相关的upload也换成set方法
						我已经有能力把所有gl里面upload的变量类型都用set包装，但是用到再说
3）cherno的debug过程。  有颜色->查坐标(用坐标代替颜色测试)->发现坐标错了，并非梯度->发现根本没设置纹理坐标，也没有重设layout（这是否下一期的伏笔
4）开启深度测试。。  texture如果三向量创建z分量设置负的,原因竟是opengl的右手坐标系
5）夸张。如果直接在着色器里让纹理坐标*10，会得到更高分辨率的图像.跑到gltexture.cpp里面加了一条_WRAP_S/T, GL_REPEAT(default)来重复；也就是平铺
6）通过上传新的统一变量和提供api的方式可以给纹理染色，很酷，vec4(1.0f)不染
7）-[LOG]-纹理坐标*10可以用texturescale这种统一变量来设置

-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Episode_48-2D渲染器04->独立着色器（小型优化）
1）意思是绑一组Vertex绑一组texture分别地做出指令有性能提升；而且事实上只是颜色跟texture不需要两个着色器，anyway，放码过来
2）合并flatcolor&texture Shader，上期伏笔，我们完全可以把纹理和颜色合在一起，只要不设置的一方自动初始化为1即可
3）通过合并shader，只需要绑定一次，不再每次绘图都绑定特定shader。   我看见了拓展，直接把drawquad合并起来同时设置颜色和texture
4）拓展API，让一些简单纹理可以从cpu设置给gpu实现(提供一个长宽的构造函数）。   -[LOG]-std::make_shared包装成了CreateRef,复杂，看不懂，但我全换掉了
5）texture+func：setdata；widthheight的构造函数跟gltexture需要width和height其实也有关系。把本地格式化和gl格式存在了类里（setdata要用
6）size参数设置了却没用是因为gl不需要而已，其他的可能要用到。
7）现在可以比较不错的设置color和texture了，goodapi

-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Episode_49-优化工具00->介绍
1）优化按部分查找，用指标衡量按部分优化。我们需要可视化工具，找到帧花费时间长或是每经过一定的帧数出现的小问题
2）参照cppseires：81 visual benchmarking.  简略查看中（发现其实做过timerclass；；-[LOG]-震惊：用到了谷歌浏览器自带的chrome::tracing
		存的一些数据变成json格式发上去；用到instrumentation插在程序里监测，用一个写文件函数，扔上去分析，包括多线程什么的不错的可视化工具，酷
3）whatever，上github抄点代码，一边抄一边学（虽然我不太维护这个）。IDE的测试工具也不错，但是自己的测试工具也notbad（学习目的更是这样）
4）没有抽象，只是一个立即出结果的小工具
5）用一次性的lambda来抓，但是std::function不好抓唯一的lambda，用了模板
6）TMD 莫名其妙出bug 又是IMGUI---没事了
		我想把它加入宏管理系统里，如果用了那个dist就删掉

-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Episode_50-优化工具01->性能分析可视化
1）承继上期，在imgui里看太弱了，转向可视化工具。（还没学vs的）
2）抄了一段代码，配置一些宏（在未来可能从一个配置中心集中配置宏）
3）总之直接抄完了
4）begin/end session好像是按文件；scope就是具体计时
5）good
6）

-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Episode_51-优化工具02->仪表
1）来试试看把这个简单的system用到项目中去，因为这个东西也是比较占时间和数据的，聪明地运用它是比较好的
2）譬如按钮，或者是延长时间什么的，只用有限的时间纪录数据。    
3）什么时候才放呢？总之，放码过来。  充满主观意愿和代码理解，看看抄抄算了，具体的应用自己体会
4）-[LOG]-windowswindow裸指针残余，-[LOG]-OrthographicCameraController现在支持旋转，有些地方析构函数什么的都没有，只能说会维护的
5）？ 不对cherno改了一次这些代码，现在甚至应该支持多窗口什么的了，我可能会彻底查看并抄写它
6）总结一下就是在关心的潜在函数那里放一个，顺便还检查出了一些漏洞之类的,代码的解释和修复(application里面做onattach也是layerstack抽象等级的问题)
	除了能看它花了多久，还能看它是不是经常被调用，还能把一整块时间切成非常多部分。；；；顺便过了一次引擎是怎么运作的
	还有，我的引擎比cherno的慢得多，我不知为何；；；runtime里面vsync会等待
	
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Episode_52-2D渲染器05->API修复增强
1）提供可选的复制平铺或是放大；原来的坐标放大也不太好，换成了平铺属性。-[LOG]-加了setvec2方法（现在比较熟悉不怕用错）
2）需要绑定这些属性，还有这些函数很多重载和参数not good，设置一些默认值（譬如1.0不变色和1.0的不平铺
3）如果创建一个结构来储存默认的属性，只修改要修改的部分 简洁可以节省开销
4）加入绘制可以旋转的四边形函数（比起重载确实更好，太多了记不住），旋转的函数开销蛮大的，改相机的时候确实也该注意一下
	所以才分出了color version和texture version吗，对API来说做比较少的事情使之统一似乎更好
5）tintcolor还没弄。   提供默认参数在编译时完成 开销并非很大
6）

-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Maintain_00 & 计划
目的是扫清原始指针，寻找cherno的代码改进相机、层和渲染、[]color * texture api；；  在如何创建一款游戏视频后，准备开工，做出demo之余再改进API
跑到cherno的commit点击file可以进去爽抄.
orthographiccameracontroller提供旋转后按照屏幕参考移动的判断(if(m_Rotation)...)/////在sandboxapp里面可以调整sandbox2D是否旋转
rendererAPI单例修改scope，增加的opengl包含转移到renderapi里面
graphicscontext同理修改scope，增加cpp文件，提供create函数。目前为止一切正常
windowswindow里静态bool glfwinitialized修改为uint32_t glfwwindowcount，为多窗口铺垫。如果没窗口了，修复glfwterminate
good，先这样，一些隐式转换是否会溢出、窗口未初始化（其实初始化了）暂时放着不管

c++20有std::barrier，但我应该用的是c++17，多线程协调以后再说

-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Episode_[53]-怎么用引擎做游戏（主要目的）
1）使用引擎的练习.
2）cherno选择的架构是gamelayer（单layer结构），level（可以和菜单之类的联动吗？），particlesystem（粒子效果），random（数学运算方面？）之类的
3）观赏一下架构即可
4）有很酷的2D粒子效果， 我也想试试，其实就是绘制一些渐淡的飞出正方形，漂亮的像素风
5）我忘了顶点数组在哪里传入的了，抽象程度一高居然忘记了现在看着的还是sandbox里面比较原始的代码
6）
7）

暂止，但是批处理渲染需要在某个节点加入
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
正在制作jumpchess小游戏
---
---
-[LOG]-我开始爆改引擎了，原始的ver在u盘里逃过一劫
-[LOG]-添加按钮类，修改renderer2D，app的遍历层event，换成了索引
cpp小知识，static标记的函数不通过对象也能调用；inline标记的函数、constexpr相当于在包含它的文件里也有
-[LOG]-整理事件系统思路，glfw窗口跟窗口API的回调和APP的onevent绑在一起，
	APP或具体绑定onevent时用eventdispatcher选择特定函数同时相当于在最后完成bool类型的真·Onevent，之前的只是接口或者回调罢了
有uniqueptr的类不给复制
-[LOG]-引擎中为按钮类增加了控制层切换的子类,引擎中开始加入键盘按钮控制
正在处理多选项按钮渲染，增加drawround
-[WARNING]-按下按钮切层瞬间会将事件传给下一层
----
----
-[TODO]-层间分享纹理相同按钮等
----
准备回归游戏引擎系列

-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Episode_[53.1]-反思和审视---回看
1）先取得基本的控制才考虑之上的效果。另外我真的需要用sandboxapp吗？
	不需要好吧，反正我可以控制layer，sandbox2D保持测试层属性就好了
2）确实渲染系统里面没有triangle，另外处理tex的东西(那个遮挡都是我+的)
3）level  Or  layer?..    Cherno相机跟随纵横比的做法（利用Onevent更新数据）但是暂不需要
	c++11的随机系统。。。。cherno给出LoadAssets的API，但是没有给出反复回来时怎么做（这个系统还是太小了）
4）还有各种问题：譬如pillar的位置写的有点tricky，但我这边已经有了一个不错的坐标系系统所以notbad
	cherno的hitbox?cherno的粒子效果？(需要查看着色器)
5）cherno也用了state来决定是否渲染

-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Episode_[54]-目标和计划（Hazel的2020计划，我流引擎升级计划00）
1）增加2D的渲染，拓展作为应用程序引擎的功能
2）从已有游戏入手该进（看来文件系统跟音频系统更需要本人的努力）
3）疑似加强渲染，加强游戏逻辑部分的规范抽象程度
4）组件会到来吗？层管理会到来吗？
5）cherno的视频不能回答我所有问题，但是足够让我意识到有什么是需要的，以及什么是必要的
6）从底层向上爬，找寻C# lua python等抽象程度更高的脚本语言解决C++不太好解决的问题(这本来也需要很多工作)主要是还有平台支持问题（主要还是windows
7）
	-[LOG]-不会禁用gameapp，提供前往sandboxapp的接口

-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Episode_55-2D渲染器06->批处理渲染（前置batchrendering series In Opengl(没看)）
1）前往前置：OpenGL系列了解:batchrendering顾名思义就是一次画几个几何图形，提高处理效率，注意，在opengl系列里没有成型的渲染器
	把做变换矩阵渲染两次改为改顶点合成一个缓冲区，然后再一次渲染两个东西。--------  那么，我是否需要更改我基于coord的渲染？
	批处理渲染和帧缓冲区合作（顶点包含各种属性），是做酷动态的基础
2）是这样的，回到引擎要考虑的就多了。我们要叫几个drawquad，跟什么纹理有关系，和我流渲染怎么结合，那都需要思考
	-[FATAL]-删除squareVerticies，大动渲染架构（已留档：alphaV1.1），靠近dynamic vertexbuffer
3）bufferdata传入nullptr：只分配空间，搭配DYNAMIC_DRAW，换了栈分配的渲染数据（也许是考虑频繁呼唤，但是栈的大小有限
	原来的vertex变成了结构体，没有弄linebuffer之类的
4）base+ptr应该是为了转移分配工作。利用ptr移动写入数据，现在看起来没用？
	噢 无敌了哥们，现在属于顶点变在drawquad里面了，真正的绘画指令在endscene附近发出
5）-[WARNING]-darwuppered已和drawindexed失去同步（但是只画一个应该还是正常的，只是extension，definitely check it out later）  --小知识，glsl语言也可以用//注释
	!!!**着色器中的u_Transform也被删除了**!!!
6）禁用所有自己的层，解决<黑屏>问题中，quadindices写入其实没有溢出问题。 会是uniform问题吗？
	说到底，我启用它了吗 因为我并未看到clear color。  对的，我没有启用它，问题解决
7）其他层是不能用这套api的，注意

-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

Episode_56-2D渲染器07->批处理渲染.纹理
1）利用起至少32个的显卡纹理单元，给一次drawquad分配至多32种纹理(一个是空的)
2）谈到纹理和其id管理，asset container确实是一个比较不错的东西，这个理念有助于解决我想解决的过度创建纹理问题，但是目前会用rendererid顶着
	发现之前初始化时纹理绑定的居然是texcoord，这也能正常渲染阿？
			-----顺便提下，
		s_Data.QuadVertexBufferPtr->Position = position;
		s_Data.QuadVertexBufferPtr->Color = color;
		s_Data.QuadVertexBufferPtr->TexCoord = { 0.0f, 0.0f };
		s_Data.QuadVertexBufferPtr->TexIndex = textureIndex;
		s_Data.QuadVertexBufferPtr->TilingFactor = tilingFactor;
		s_Data.QuadVertexBufferPtr++;
		真的是太像cpu端整合gpu的vertexarraylayout了，批处理渲染也解决了单一统一变量上传不便的问题

3）-[Warning]-cherno给texture数组的初始化方式在core330中被认定为不合法，我将切换为core460
4）着色器用错变量或者统一变量真的是很难排错
5）我疑惑为什么index不自增的伏笔回收了。这样果然会导致纹理出错
6）cherno也会对debug发出疑问， that's true。 着色器的代码非必要不更改，至少要存档
7）奇怪，纹理交叠处会有一些噪声，是a卡的渲染优先级不同了吗
	有点看懂了，这样做几乎摆脱初始化顶点数组，因为它已被神奇地在drawquad里被分配；但是代价呢？我似乎失去了原来0.5 0.5的固定大小，也就是说：
	-[LOG]-由于顶点数组中固定的大小参照坐标已失去，crazy
		又出bug了，抽象显示。果然是layout的大小弄错，复制粘贴增加顶点属性时应当留心它的大小，匹配错了就会因错位而扭曲

-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Episode_57-2D渲染器08->可旋转的四边形----覆写转换矩阵
1）转换矩阵也许不是必要的，也许不是最快的，它的存在就像是对可读性作出妥协，就像是高手做题目列出了额外的思考步骤，会让我这种入门的朋友审视代码的时候更清晰明了，所以我写的东西也应该保持这样的风格，哪怕牺牲一些性能也要保证至少可读可维护。
2）峰回路转，回到了有顶点的风格，果然和我想的一样，这只是把drawquad的指令移到了最后面，但是顶点的绘制方向是顺时针吗？不是，大概是翻译错误
3）使用转换矩阵暂时也是为了保持风格一致，和之前的api的做法也一样，有一些属性（默认的）是重复的，可能用一个循环更好
	奇怪，核显情况下rotation的更新只出现一帧，float溢出了，但我记得timestep重载了操作符阿，但是确实一次就溢出了, ts * rotation数字明明是正常的，一旦加起来反而怪了
		不理解，重载下项目试试看吧，不行，why？ 和ts相乘时就会出错，怎么旋转相机就没事。   将20.0f * ts赋值给static变量时出错，是作用域问题？但是成员变量也不行


	-[WARNING]-未解之谜，staticfloat存储ts*float试图得到一些动画时候出错，存取的数据很奇怪，怀疑是ts在等待启动时也计算了
		-[LOG]-半成品批处理渲染副作用超级大，Beginscene试图增加了清除上一次得到的纹理或者什么的东西，几乎没有作用，再次大改试试看
		

-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Episode_58-2D渲染器09->统计信息、批处理改进、一些尝试
1）一部分是用于追踪是否运行，另一部分是提供一些测试平台，为优化提供一点点平台，但我并不想这么做
	在用我构建的层测试渲染，发现texslots只会更新，而似乎不会在另一种beginscene清零，和redererid也有关系，更坏的是vertexarray怪怪的，只有init初始化的话切层肯定出事吧
	到此为止，我发现现在的批处理还差的远呢
2）统计信息之类的如果如果不需要完全可以用一个宏来禁止它
3）现在可以统计渲染矩形个数、、等等

4）cherno有给出一个粒子系统的实现：OneHourParticleSystem，可以参考，总之为了一些比较酷的东西，我们把它整合进来了
5）神奇黑屏，检查中。
6）笑嘻了，居然要滚下滚轮什么的更新先。不过也真挺神奇吧，简单深度处理居然就改z轴就解决了
7） 粒子系统其实就是一个很酷的随机方块移动等等，有些参数，逝去时间，大小什么的可以调，其实还是蛮不错的
      cpp小知识，初始化列表:....的顺序由类里面变量排序决定而不是在列表中给出的顺序
	这个很酷的粒子系统需要相机，definitely check it out

-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Episode_59-2D渲染器10->纹理图集、精灵图(sprites)的原理
1）就是一张图里有多种纹理，按照一个方式把纹理里面的像素转换为纹理坐标，这也是之前看到如同展开图大小相似的图合并的原因：等大小更好映射
	that is to say, 坐标转换系统又要出现一个了，这个是纹理的
2）安装aseprite回来，发现cherno的代码和我超级不一样，cherno应该已经作了不少维护工作和更新。我要做的呢就是把这些分割精灵图的方法抄下来慢慢理解。而且我现在没有任何一个精灵图，我将会用cherno的图片作辅助，
	或是等待spritesAPI？-[LOG]-记住这件事
3）要做的事情就是修改textureCoord，只上传一部分给它，提供一种自增的机制，按顺序，或是按需要取用，利用子纹理的等距特性。
4）好处是不需要多次绑定texture，事实上，这也是一次batchrendering
5）一个精灵图被拆开的时候做成subtexture很好，如果对同一个对象按时间索引某个动图texture，那么显然能做到动画


-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Episode_59-2D渲染器11->subTexture; 精灵图接口
1）subtextrue不需要平台特定的实现
2）给出的函数一个是基于像素坐标创建子纹理，另一个是基于纹理内纹理关系的坐标转换成像素坐标创建子纹理
3）还没有做完，因为和之前有点不一样也有点复杂，在思考中，精灵图接口到底要怎么创建，到底要怎么用？这和我们的渲染如何搭配会简单又高效？我们是否需要维护代码？明天也许会给出答案
	我会做的是: 抄点代码！目前抄到quadvertexposition
4）issue: 精灵图不如预期那般分割开来，检查api
	？ 这是一个额外系列吗？我没有在hazel里找到源代码，我只能检查了
	似乎突然又可以了。没有深度测试，于是启用深度测试
	提示，精灵图索引也从0开始

-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Episode_60-2D渲染器12->贴图映射演示
1）并非文件类型的tiled map，cherno会演示一个比较简单的方式
2）本质上是用一种文本或是数字表示贴图，在顺序读取渲染的过程中依据给出的标识渲染对应的贴图，也就是所谓的画地图
3）利用内存的连续性顺序读下去会更快
   画出来是倒置的，对的 这就是gl的特性，如果用drawquad只需将绘画时y坐标倒置即可。
4）神奇的一期，我会说这个功能展示了subtexture的一种用法-与unorderedmap结合
	但是这些特性都是比较原始的，仅仅起到展示的作用。它甚至不能接受文件流
5）为引擎添砖加瓦的一步


-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Episode_61-编辑模式工作流00->dockspace
1）本期目的是减少一些临时ui界面编写，和后续搭建好部分系统后与C#接轨
	嗯，对的。是让imgui调试不同纹理渲染等等的ui,此前就折腾了很久，也有一个临时的dock，暂时看不到对我的项目的帮助

			-[WARNING]- I have skipped this episode without code stolen



-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Episode_62-2D渲染器14->帧缓冲创建
1）事实上是回归了主线：正常渲染。现在的示例视觉代码并非原来代码，
	不是不抄，而是要辩证地抄，要聪明地抄，要边思考边抄，边改进边抄。
2）是时候改变野兽派的疯狂drawquad了，利用framebuffer，可以把一些需要或者想要打包渲染的玩意实现，免得hardcoding
	参照framebuffer,renderer2D和window,把数据和类的属性分成一个struct和class将会更加便于处理
	这里面的变量通常做大写开头欸
3）Renderpass的概念，通过渲染通道执行了一次完整的render
	some glcodes， colorattachment可能是绑定slot0那个无色纹理，depthattachment不知是何物

	----原因是----帧缓冲实际上包含了颜色缓冲设置、深度缓冲设置或是模板缓冲设置等缓冲设置，和vertexArray一样，如果我们不客制化它就会用默认的
4）ohno,由于演示放在了imgui里面，我暂时不会知道这个东西怎么用（为何用的是textureID ner？）下次我会检查
5）于maintain期间了解它

-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Maintain_01. 向下兼容之路
1）兼容原来的渲染之：清除顶点数组缓冲和纹理尝试？
	试图memset似乎不行，想用imgui调试结果发现莫名其妙8行
	嗯，断点说的是我忘记结束了，是上下文语法不对，再找让其他layer可以稳定统计drawcall perframe，在update里面应该会有清除才对
imgui的stats是测不出来的，现在只能跟踪给出的渲染指令，不能追踪gl里面的绘图，包是里面出问题了
	datasize正常，并未正常调用clear，disablelayer的时候为什么没有进clear？
发现layerstack内部shiftlayer是调用enable和disable实现，但是在application的API不是，
所以application里面但凡是要disable或者enable都必须要调用一次clear
	？清0之后还是显示太刀，同样并未tintcolor-[tintColor已解决]-
2）继续找原因...  ...
	把粒子系统加入menulayer试试看能否顶掉太刀？ 不过粒子为什么会不显示？
	全乱了，粒子系统只能暂时顶掉一些奇怪的渲染，如果用粒子顶有新渲染bug，出来的东西可能是混乱的纹理，问题的根源会是渲染内部吗 会是批处理渲染吗？需要了解它的真正工作原理才能debug吧
	-[检查vertexbuffer]-
3）写了只提交1个的函数依然出错，particlesystm的鼠标位置判定也怪怪的(相机不同还会被移走)
	嗯，为什么在外面的layer也可以用sandbox2D的event？这会是application的层交换系统不当导致渲染不当的问题吗
	【Info】疯狂切层的时候会有些层的enable被错误设置。
	我清除相应的顶点数组和纹理之后屏幕依然错误显示，
	particleSystem可以清除掉这些画多了的东西，但是也不一定，而且同样它也可能不被清除(切层时)，切层多了依然会串
	sandbox2D被settrue,不是因为别的，而是因为ESC会按第一个按键，然后它就来到了sandbox2D，仅此而已
4）渲染opengl应该是即用即弃的状态机模式，先前的状态为什么会被不当地保存呢？而且还是在batchrendering才出现.. .. ..
	that's absolutely wired.并非显卡问题，
	我现在百分百确定是batch rendering和drawbutton链接的逻辑有缺漏，绘图里面的一些噪音也是新增的问题
	但是我不熟悉opengl，总之先尝试更改sampler、maxquad等等，这也太怪了。也许particlesystem可以用来当切层渲染异常的探头
	现在可以确定的症状是，如果没有更多quad被渲染，上层的quad就会一直"静态"地被渲染，particle也是一样，在本层渲染之中才会消失，太刀的跳图层应该也是这个导致的，也是多的那种.
5）-[LOG]-为buffer新增invalidate方法，参考framebuffer, 并未解决问题
	我更加确信是某种程度上的错误调用，而且它和某一次的填入数据有着莫大的关系
	先做了补救措施，为所有层添加粒子效果,当然这个粒子效果也很原始，太大了,修正了
todo: ***删除各种数据,glinvalidate/glbufferdata/glbuffersubdata
	试图删除各类缓冲经过测试无用/副作用极大，可以考虑就用这个临时效果先修，所幸作用上是一致的
todo: **剔除噪点，推测与dynamic draw有关
todo: 规范化共享化粒子特效

	试图重新分配缓冲区但空指针错误...   当前缓冲数据毫无疑问保存在本地，但是在哪里提交的？
	在setData提交之后绘图，能提交却不能绘图。。 那bufferdata和subdata有何区别，既然都是一次提交为何不直接bufferdata
	嗯 用bufferdata暂时处理好了
	神奇，噪点也大大减少了,那就只剩下噪点的额外尝试了，framebuffer暂时没兴趣
	嗯 我怀疑跟分辨率有关系

向Sandbox中各种项目以及引擎对应部分整合subtexture等功能... ...
	-[LOG]-不理解framebuffer的作用。但在Menu带上它了也没有出现问题,也许为渲染提供方便？

-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Episode_63~66-编辑模式工作流->创建新项目，创建编辑系统
1）
2）     ----------------SKip--------------
		补场景视口，狠狠地朝了一大堆看不懂的玩意,,,遗留的代码还没清理	

3）
4）

MAINTAIN--审视引擎清理代码,学习重构
By Cherno
Core.h新增多平台编译支持
holy,不少改变,确认原先的是否工作,premake是否更改？等等
是否去掉LOG等等的，是否也该为我的sandbox添加预编译头？
also include window.h如果放在上面底下会有一点不同
keycodes向本地化过渡，做成enumclass

refactored Input类,其实就是去除了windowsinput.h,这样也不再需要单例模式
顺便也改成了自己的枚举类，这样做虽然不会比宏方便，却有利于c#入场
OK 完成,以后要写成Engine::MouseCode:: ... 了

-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Episode_67-实体组件系统00->intro/chat
1）具体来说，这是非常重要的，非常高手的部分，并且是我们开发的一个基础(显然)，可以知道的是我们要用一个库
	那么先听听实体组件系统到底是怎么样的，怎么工作的，要怎么做
		ECS journey Started!
3）使用entt库的原因:entity系统难,对系统性能作用非常重要,就好像要使用数学库和优化一样，是取舍了编写时间和学习的决定
但是编写自己的entityComponentSystem当然有好处,我编写的非常非常原始的button事实就能够加深我对游戏引擎的理解了
	entt layer? 我应该暂时不会做成imgui那种Editor的形式，我会先允许我的layer存在
	用Scene来统领联系player等entity,为它们的行为提供数据
4）Scene保存entity的列表可以为我的button提供参考
 entity到底是什么？entity可能存在不同的属性. 可能使用inheritance,或是让某些属性单独成类,按需组装
 	譬如mesh(看起来像是某种模型)light,
 但是我不认为inheritance是个好办法，继承关系非常乱，最后每个东西都相当于自己重新写了，种类越多越复杂
5)Component确实和前几期学的那种很像，之前那个可以说是数据结构和行为分离，带有一点组件的思想，
 component显然需要遍历更新，需要update方法
6)需要做设计让同一种属性的东西在内存里相邻，这样可以超级快速地取出
	比起遍历entity，直接遍历component，然后查询是否有对应entity编号的component显然更佳
	entity其实就是编号，是组织各种组件的一个辨识符

-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Episode_68-实体组件系统01->加入entt,介绍entt
1）选择和cherno相近的版本，摸熟悉了再跟进成现在的版本
	entt是模板头文件...  注意核心思路是scene管理entity，entity又由各种组件组合而成，registry就是一个关键线索
2）entity实际上和renderer什么的实际上其实都只是一个数字，一个uint32_t，所以没有entity. ...  只有m_Registry. ...
	用struct做component(本质上只是数据结构)，这样就可以避免过于复杂的继承结构了
	**展示了默认构造函数,默认复制构造函数,真·构造函数的三重存在(有时候会用到)
3）cpp小知识:--如果强转不被编译器认可,取指针再解引用依然可行如 *(CastType)var
4）酷，这给了get的同时构造的时候也返回一个引用，也有像unorderedmap那样的查找特性，这种结构确实值得学习
5）介绍了一些registry的功能，展示了一些不是很懂的酷东西，其实是跟这个库的示例代码有关系的，示例就教了很多普通的应用方法
	譬如没见过auto& view = registry.view<Component>();可以取得一个迭代器？
	比较奇怪的是迭代器的名字用的是已经有的entity,而且在里面能够取出来
6）学会一件事，鼠标移上去看函数的注释，可以得到很多信息
	还有神奇的on_construct函数,又可以来个.connect来绑定具体的实现函数，需要取地址
	这种自由度应该也是来源于强大的模板,想你了std::func

-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Episode_68-实体组件系统02->进行渲染工作
1)悬念消除，lastEpisode学来的东西需要debug，得出的结论是:不能给空的组件 -[LOG]-事实上属于exception
2)好的，cherno即将用imgui进行测试,而禁用了imgui的我选择是在sandbox2D测试，该学会只添加我需要的功能了
	简单折起来了sandbox2D,想起来framebuffer那个若有若无的作用
3)有点像把渲染要求重新转移到scene中去,感到任重道远
4)开辟新的文件专门放component了，要重新把渲染的矩阵，颜色，纹理等等等等重新放进去
	感到emplace的语法怪怪的，像是多了一个选择entity的构造函数
5),ecs要用矩阵来做drawquad的基础(确实这样简化了api),rendrer2D于是有了新函数,但我相信它略加修改可以向下兼容
	只是把计算转移，这样也能再次减少代码量
6)不错，但我应该会在真正用到的时候或是维护时间去清理,让外部API更加简洁
	另外一个小问题，并非中心绘画

-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Episode_69-实体组件系统03->构建自己的Entity类
1)本地化需求 * 客制化API(参考opengl等等封装)，所以写entity类包装一下
	想要在客户端里像Editor一样无需考虑过多实现细节意味着实现的细节要更多地在引擎内部完成
	这次的目标是可以让无组件所有权的实体一定程度上呼唤组件。
2)建立entity类是个线索，应该说是增强用的库的抽象程度和本地化的再次提示，可以预见所有外来系统都应当要被封装一次
	不过api的名字应该要和原来的那个有些关联，方便管理查找对应.....
	.cpp小知识，模板和友元很强大,cpp series的时候只知道模板是编译器帮忙写代码，没想到是什么潜在可能的类型都能自动匹配上
3)用神奇的模板做好了一些封装API，不知道怎么用
4)但是entity的对操作做出反应的组件cherno还没添加，只提供了都有的transform等
	评价是不如
4)呃怎么entity创建API在加入新的Component的时候会说已有comopnent呢？而且重载操作符的时候也怪怪的
	嗯. 刚创建出entity就有这个component了，噢wtf，应该要取反吧，没有返回false才对
5)handle也不对，还是说依然还是从0开始的？应该是计数才对吧，为什么我取得的handle为0呢
	漏洞百出？第一个的handle得到是0，而且后续取出component的时候报错说没有，为什么呢，
	噢 是我太困了，assert逻辑写错了  实在不是很理解这个系统。 imgui更改颜色时出错,然而其它时候不会出错，果然是flatcolor的问题
	那应该就只剩下最后一个问题:为什么handle从0开始, 而且cherno可以用不等号，库是同一版本的...   ...
初步认定不对劲，索引就是从0开始的，cherno的东西怎么回事呢？但我也看不到他调试看不清
	那么初始化为114514把(哎这就是码风啊)

-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Episode_70-实体组件系统04->和ecs配合的相机系统
	-[WARNING]-解释了上一次overload的错误:使用0而非entt:null,但这么做我会遇到错误，因此我保留114514的做法
	动相机系统很好理解，渲染其实就基于相机给出的transform,之前的比较原始
	(只有一个用底层算的的正交相机),最重要的是ECS中需要相机,所以做了抽象的相机类
1)cpp小知识,返回引用其实才是自然的想法...    ortho矩阵参考ortho相机
	view是单component,group是多component,,
2)camera是为渲染服务的，至少需要那几个变换矩阵来得到transform
	想要实现的办法有很多，可以丢camera，可以放renderrer里做struct也可以就在component里面
	cherno最终选用的是在beginScene传入transform
3)小技巧，用指针初始化nullptr在很多情况下方便得出是否成功初始化(可以用if(ptr)来判断)
	和我原来想的不一样，其实所有东西都是实体，我以为是按钮才叫实体来着
4)又是bug, beginscene第二个版本报错连接错误，原因未知-[LOG]-命名空间错误
	又是bug,	 auto group = m_Registry.group<TransformComponent>(entt::get<SpriteRendererComponent>);崩溃
	gpt给了个组件不一致的提示，-[ERROR]-断言问题，找到一种可能解释如下：
-------------                        -------------------------                        -----------------
假设有三个组件：CameraComponent、TransformComponent 和 SpriteRendererComponent。
用这三个组件在代码中分别创建了两个 group：
第一个 group：group<CameraComponent, TransformComponent>()
第二个 group：group<TransformComponent>(entt::get<SpriteRendererComponent>)

什么是不一致实体？
考虑以下场景，有三个实体（Entity A、B 和 C）及其各自的组件：

Entity A:
组件: CameraComponent, TransformComponent
Entity B:
组件: TransformComponent, SpriteRendererComponent
Entity C:
组件: TransformComponent

根据这些组件的分布，以下是 group 操作的结果：

group<CameraComponent, TransformComponent>()
结果: 只会包含 Entity A，因为只有它同时拥有 CameraComponent 和 TransformComponent。

group<TransformComponent>(entt::get<SpriteRendererComponent>)
结果: 只会包含 Entity B，因为它有 TransformComponent，并且 SpriteRendererComponent 也存在。

断言失败的原因：不一致的实体

在这个例子中，Entity A 和 Entity B 是“不一致”的实体，因为：
Entity A 存在于第一个 group 中，但不在第二个 group 中，因为它没有 SpriteRendererComponent。
Entity B 存在于第二个 group 中，但不在第一个 group 中，因为它没有 CameraComponent。
这种不一致违反了 ENTT 对组的一些假设：
在某些特定的 group 组合下，某些检查（如 ENTT_ASSERT）期望组件组合在所有相关 group 中是连贯的或一致的。
-------------                        ------------------------                        ---------------------
嗯，排除square时依然报错，排除camera之后就不报错了...真的是group冲突问题吗，我都销毁了原来的group了？
github上面有简直一样的问题和答案https://github.com/skypjack/entt/discussions/681
具体来说两个组不允许拥有同样的组件,如果真的要用，那么就用view

	也是不太跟cherno的一集..   ...
	cherno下次给了view的解决方案

-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Episode_71-实体组件系统05->sceneCamera
	追上orthographicCamera的resize功能,是否修复aspectratio的两种
1）这个功能和EditorLayer中加入的视口功能有关,我现在开始思考ECS是不是相当于把之前的系统拆成组件的接口放在每个实体上，利用遍历来更新所有实体就相当于之前直接更改渲染（这样肯定有更多的控制）
2）锁AspectRatio或者说就是projectionMatrix的一助攻做法是只定义一个size，另一个跟aspectratio相乘（这也是老相机做的事）
3）抄！抄！抄！，无法访问的的什么问题升可见性解决就行，orthographiccamera里都有参考
	发现部分代码缺失无法渲染应当存在的这个矩形，回头排查
	于是整理一通代码,我现在确定应该是viewportSize是0的问题了,cherno应该在imgui里面做的,尝试初始化非0无效
	...   ...怎么办呢, aspectRatio怎么能是0呢
	继续抄imgui的东西，发现还是没有enable或是开了双修改

	-[WARNING]-FRAMEbuffer不能随便抄,会把原来的也黑屏  //  于openglframebuffer::bind中
	现在可以确信完全是某些视口设置出现了问题，但我不知道在哪里出现了问题,我会保留能跑的那一部分，sandbox里面做冷处理？

-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Episode_71-原生脚本->开始让引擎变得像引擎
---无限期搁置


-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
再次进入jumpchess...    ...
我必须考虑是否采用ecs,感觉它暂时高级难用,先按照这个架构做出来再考虑大修..?

但我先得把camera修好,-[LOG]-maintain..整理camera让它至少能正常渲染,嗯,aspectRatio没更新导致的...    ....
我选择彻底不做ECS，做好buttonList各种东西再说
buttonList不做了

计划添加audioSystem , powered by openal, which has similar api as opengl
以下开始
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
m_Edit-00->音频系统->介绍和加入openal
1)openal和opengl有着不少的相似性，构建的音频系统应该和渲染系统会比较像
2)我想要用premake加入，但是我不清楚这个代码架构，没找到src文件到底是哪几个。
-[LOG]-但我还是写在premake里了，目前是用cmake编译了
小知识，呼叫vs的cmake工具的方式：call "C:\Program Files\Microsoft Visual Studio\2022\Community\Common7\Tools\VsDevCmd.bat" -arch=x64
3)openalsoft编译出来一个挺大的解决方案，明天再研究
	前往官网一探究竟
	听说也要vender给includes，然后介于有dll莫名其妙自己就能连接上，真厉害吧都(什么opengl32)
	留下了libdirs{}没填的悬念,换成了core那个版本，寻找示例代码中
4)assets中添加了新的文件夹放sound
5)经历艰难险阻呢终于是做好了加入lib，没有连接错误了，但是文档很少，示例代码都没有几句 sosad
6)搁置了，有空再弄 我要放假了

-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
m_Edit-01->音频系统->openal挣扎
1)读取文件产生问,尝试使用alut, 大失败, 尝试其他库，不成功，重新试图封装播放，未成功
2)   -[LOG]-由于封装程度低，openal现在对客户端暂且设置为可见以便调试
3)参考代码得到了简陋的.wav播放功能，当前接口在引擎中(和刚加opengl的时候很像)分别有loader和player两个简陋的分类
4)现在有了一两个堪堪能用的类，现在就算是拿下了openal的基础接口属性：buffer,source,device了，相当于画出了一个三角形
	下一步的审视:开始构建api,探索ALapi的其他功能

-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
m_Edit-02->音频系统->openal探索和思考
1)allistener表示聽者所在的方位(和聲源的alsource類似),同樣用3f,i等等的後綴表示上傳的數據
2)調節增益屬性用的是alsource中AL_GAIN參數,這個提交的方式很像上傳給shader,在chrome裏收藏了一頁可以簡易查詢。
	pitch會升調
和opengl那裏一樣發出playCall的時候傳參也許是個好辦法，但是我有時候需要對某些音頻產生效果,我需要持續檢測狀態,不如説音樂持續和渲染動圖更加類似,我怎麽接著播放下去可能會是關鍵？
3)play本質上也是提交一個bufferID(that is alsourcei)
4)al上下文是直接持續打開,還是和opengl一樣只在需要的時候呼叫並提交？ 這和内存的管理有什麽聯係？(很顯然我不想近乎全局地持有.wav)
	我需要的api的形式是怎麽樣的？它如何參考opengl的形式構建架構,它是否和opengl一樣以不可見的形式放進platform文件夾中？
	考慮到openal的要素是device(大概相當於gpu?),buffer,source,context,
	和opengl的結構貌似只有相機,buffer和player等等可以參考,可以做聲音2D運動效果。。。最重要的是：需要player2D嗎？ 應該會做
也許是因爲找到的教程的episode 3,4是一個3D的

-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
m_Edit-03->音頻系統->開始像opengl一樣建立openal架構
1)-[MAINTAIN]-drawuppered更名為drawcovered
2)建立大量類似文件，開始抄寫
	第一難:初始化工作裏device是一個實體,純虛AudioAPI事實上什麽都做不了, 也許先抽象buffer等？
	由於device在實際播放中并不為我們所關心, 在ALAudioAPI的實現中把它作爲成員暫存,只作爲打開/關閉音頻功能而存在
3)下一步：Buffer和它的fileLoader
4)如火如荼地進行中,但是同樣存在一個問題：怎麽得到device？總會有辦法的,到時候不行就整合
5)下一步事項：api裏面要有playsource需要source,外面context需要api的device,合起來會不會更加方便呢？
	應該要把context放到API裏面合起來的。但是現在先把source做了
6)source的上傳和shader或者uniform極類，而且-[LOG]-已發現source的功能有play stop pause 還有倒帶, 自帶的多source自動管理等

-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
m_Edit-04->音頻系統->讓openal架構工作--audioPlayer2D
1)bind和unbind還沒有加上，先從player2D的構建開始完成框架再回填！
	把播放的功能最終還是放在了api上,context就有點不管他，最後決定刪除了
2)現在應該有了一個ok的底層架構，圍繞beginscene等再做一些文章————需要相機嗎？怎麽利用？它的意義是提交還是控制？
3)先不加相機.感覺audioplayer還是和renderer不一樣
	尤其是批處理渲染讓這個audioplayer的構造更顯撲朔迷離：我支持多源嗎？我支持多源的方式是在客戶端定義還是利用player統一管理？
	多源的播放是怎麽做的？(我覺得該有addsource,mutesource等等方法,以構建一個和render不甚一樣的體系)同時我要怎麽解放一個源
	(因爲audioplayer是全局的,源則是可變的,buffer裏的數據更改方式是不一樣的(因爲我常常只是加載,播放它而不是創造一些聲音))
	openal的混響效果如何呢？先不管

-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
MAINTAIN_02->文件管理->管理包含關係的名字
	現在所有有直接關係的頭文件(抽象度高的超集如renderer<-renderer2D)直接使用相對路徑
	有需要關係的其他文件用相對路徑根目錄出發的版本,如Engine/Renderer/...
	外來庫文件(相對正式)或在客戶端呼喚引擎使用尖括號
	涉及文件夾：Audio,Renderer
	审视提供一些可能断言和部分必要日志

-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
m_Edit-05->音頻系統->完成openal架構修理問題
1)現在給予客戶端以名字的方式管理source,參照shaderList啓用sourceList和bufferlist, 添加create方法
	粗略的消抖不能讓source的暫停之後正常播放(然而逐行運行時可以)
2)提供的全局修改增益等功能無法使用(因爲play裏面提供了修改增益的方式)
	考慮做乘積？   sourcelist等提供了迭代器遍歷,-[LOG]-新增析構方法,會解析所有source和buffer
3)基本做好了,下次將要在客戶端和其他屬性一起提供全局修改功能(譬如音頻增益,音頻,粒子效果 等等(填充setting))

-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Epidode-72->实体组件系统06->相机组件
1)
2)
3)
4)

-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
m_Edit-05->音频系统的全局调整
完成了，利用哈希表自定义名称统一管理音频。
现在可以全局修改增益

-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
m_Edit-06->支持Xbox手柄->利用起glfw的输入
1)在input类里加入了检测手柄的函数，准备了一个静态的state以供更新
对于线性元件（尤其是两个摇杆）我使用它们和中心的距离应当比较大消除了偏移导致的误输入
现在可以灵敏地检测到手柄的输入了！

-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
m_Edit07->支持键盘手柄->所有类型button的适配
1)template<typename... Args>
Log(Args... args);
2)初用模板，头晕眼花。尽量贴近底层的想法做，模板套多了不是好事。	
	---c++小知识：decltype关键字可以检测一串表达式的类型而无需计算它
	--cpp小知识。当你尝试使用 std::anyof(a.begin(), a.end(), [&](typename T var){ return xxxxx;}) 
		检查一个可迭代容器中是否存在满足条件的元素时，将元素类型而不是int i这种东西传递给lambda
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
m_edit0809->支持键盘手柄->锦上添花
1> buttonEffect史诗级强化，现在可以输入一个序列非常便捷地管理键盘和手柄的输入/事件，并且妥善地管理button状态
2> button类的onEvent和onUpdate重写更新后引入防抖，将许多代码迁移到类里，令Layer的代码非常简洁了
3> 动了Engine的Event类，但是没有什么用，主要拓展了Input类。
4> 为了方便下棋， 提供了全新的QuickChoose方法，本质上只是遍历一个序列，但事实上有利于开局空间位置的快速变化。
5> 绘制操作表，准备了右上角悬浮根据当前输入设备来显示的功能(thanks to Event分类机制)

-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Epidode_72(true)->实体组件系统06->相机组件
1)重新出发，继续将我魔改过的引擎继续下去。
2)从跳过的Episode_61开始，将包括dockspace的gui和C#脚本内容跟进一下，了解一个引擎到提供脚本，给出编辑空间到底是怎么工作的
3)
4)

-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
